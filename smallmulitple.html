<!DOCTYPE html>
<html>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/vega@5"></script>
<script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script>
<script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@1.5.1/dist/tfjs-vis.umd.min.js"></script>

<style>
  body{
    background-color: #eeeeee;
  }
  p{font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif}
  td, th {
  border: 1px solid #c0c0c0;
  text-align: left;
  padding: 5px;
}
tr:nth-child(even) {
  background-color: #cacaca;
}
option:hover{
  cursor: pointer;
}
.tooltip {
  position: relative;
  display: inline-block;
  border-bottom: 1px dotted black;
}
.tooltip .tooltiptext {
  visibility: hidden;
  width: 320px;
  background-color: #555;
  color: #fff;
  text-align: center;
  border-radius: 6px;
  padding: 5px 0;
  position: absolute;
  z-index: 1;
  bottom: 125%;
  left: 50%;
  margin: 0px 0px -60px -60px;
  opacity: 0;
  transition: opacity 0.3s;
}
.tooltip .tooltiptext::after {
  content: "";
  position: absolute;
  top: -35%;
  left: 50%;
  margin-left: -5px;
  border-width: 5px;
  border-style: solid;
  border-color:  transparent transparent #555 transparent;
}
.tooltip:hover .tooltiptext {
  visibility: visible;
  opacity: 1;
}
  .sidebar {
    height: 100%;
    width: 0;
    position: fixed;
    z-index: 1;
    top: 0;
    left: 0;
    background-color: #111;
    overflow-x: hidden;
    transition: 0.5s;
    padding-top: 60px;
  }

  .sidebar a {
    padding: 8px 8px 8px 32px;
    text-decoration: none;
    font-size: 25px;
    color: #818181;
    display: block;
    transition: 0.3s;
  }

  .sidebar a:hover {
    color: #f1f1f1;
  }
  .closebtn{
    margin-top: 680px;
  }
  .openbtn {
    font-size: 20px;
    cursor: pointer;
    width:  150px;
    background-color: #111;
    color: white;
    padding: 10px 15px;
    border: none;
    position: fixed;
    /*display: none;*/
  }

  .openbtn:hover {
    background-color: #444;
  }

  .reg {display:none;}
  .parameter_button{
    cursor: pointer;
    background-color: #ffffff;
    border-color: #cacaca;
  }
  #main {
    transition: margin-left .5s;
    padding: 16px;
    display: none;
  }
  #explanation{
    display: none;
  }
  
  @media screen and (max-height: 450px) {
    .sidebar {
      padding-top: 15px;
    }

    .sidebar a {
      font-size: 18px;
    }
  }
 p{font-size: 18px;}
  #parameterdiv {
    background-color: #eeeeee;
  }
</style>

<body>

  <div id="mySidebar" class="sidebar">
    <a href="javascript:void(0)" onclick="closeNavAbout()">About</a>
    <a href="javascript:void(0)" onclick="closeNavTraining()">Training</a>
    <a href="javascript:void(0)" onclick="closeNavExplain()">Explanation</a>
    <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a>
  </div>
  <div id="stats"></div>
  <button class="openbtn" id="openbutton" onclick="openNav()" style="font-size: 90%;">☰ Open Sidebar</button>
  <!-- <button id="openbutton" onclick="getTestResults()" style="font-size: 90%;">Tests</button>
  <button id="openbutton" onclick="showTestResults(testtime,memoryUsage)" style="font-size: 90%;">ShowTests</button>-->
  
  <div id="about">
    <div style="margin:auto; width:30%;">


<h2 style="font-size: 200%;">How does a Neural Network learn?</h2>
    <p>
      You've probably heard of artificial intelligence. It is being used everywhere. 
      Weather forecasting, autonomous cars, image processing, medicine, research, 
      and more. But what exactly is AI? This type of intelligence describes the ability
      to act appropriately and proactively, to perceive and respond to sensory input.
      The goal is to mimic human behavior by learning from data. A subclass of AI is
      deep neural networks. They consist of interconnected neurons. By adding data,
      training, and evaluating right or wrong, the connections (also known as weights)
      of the neurons are strengthened or weakened. The algorithm is often presented
      as a black box model, where the user does not know how the training actually
      works. We want to change that!</p>
      <h3>
        From the Black Box to the White Box Model
      </h3>
<p>
  For some time now, there have been efforts to make AI and neural networks more 
  accessible to the general public. <a href="https://playground.tensorflow.org/">Tensorflow Playground</a> is one such tool. It 
  allows you to train your own network on a dataset and see the weights of the 
  connections as well as how the neurons divide the data!  Some parameters are not
  learned by the network and must be determined before training, the so-called 
  hyperparameters. The number of possible connections for a hyperparameter set is
  exponential. With our tool we want to show how the number of neurons and the weight
  initialization can influence the evolution of a neuron.

    The <a href="javascript:void(0)" onclick="closeNavTraining()" >training section</a>
   allows you to create your own networks. We stay close to the Tensorflow Playground model, limit the
    choice of hyperparameters and provid a small multiple so that you
     can get information about the effects and the ability to compare 
     with similar networks. A more detailed explanation of each 
     subchart can be found in the <a href="javascript:void(0)" onclick="closeNavExplain()" >explanation section</a>.
    </p>

    <h3>Concepts to help you to understand the training process</h3>
    <h4>Function Approximation</h4>
    <p>
      Predictive modeling is the problem of developing a model that approximates a function using historical data to make a prediction for new and unseen data.
      In general, the function approximation task can be divided into classification and regression tasks.
      Classification is the task of approximating a mapping function from input variables to a discrete output variable. In our tool, we provide points, that are either part of class one or class two.
      Regression is the task of approximating a mapping function from input variable to a continuous output. In our tool, the positional encoding can take any value between -1 and 1. The output
      is also often referred to as a label.           
    </p>
    <h4>Artificial Neuron and Multi-Layer Perceptron</h4>
    <p>
      How does a deep neural network learn to map input to output?  A neural network learns with 
      so-called artificial neurons. As shown below. </p>
      <figure>
      <img src="img/neuron.png" alt="Artificial Neuron" width="100%">
      <figcaption>An artificial neuron.</figcaption>
    </figure><figure>
      <img src="img/nn.png" alt="" width="100%">
      <figcaption>A fully connected neural network.</figcaption>
    </figure>
      <p>
      A neuron receives a number of input 
      values. These values are multiplied by a weight that is learned during the training process. 
      Now, everything is summed up and the sum is used for an activation function. In a deep 
      neural network, multiple neurons are arranged in layers, where the output of one layer 
      is the input of the next layer. Thus, the network learns by adjusting its weights.
    </p>
    <h4>Backpropagation</h4>
    <p>
      The weights are adjusted during the training process. The training includes three stepts, the feedforward step, the backpropagation and the update of weights step.
      In the feedforward step, data is send throught the network. In the output layer, a costfunction is calculated. As example the Mean Squared Error function, that calculates 
      the distance between the models prediction and the label of the data. To minimize the error, a scaled negative gradient is calculated for each neuron. This is done 
      layer by layer. At the end, all weights get adjusted according to the costfunction.


    </p>

  </div>
  </div>
  
  <div id="main">
    <h2 style="margin-left:350px; font-size: 200%;">Influence of a Neuron</h2>
    
    <div id="parameterdiv" style="display: flex; margin: 0px 0px 0px 150px;">
      <div id="dataplot" style="height:200px; width: 250px; margin-right:50px"></div>
      <div id="parameters">
        <label>Type of Problem: </label>
        <select id="networktype">
          <option value="classification">Classification</option>
          <option value="regression">Regression</option>
        </select><br>
        
        <label>Selected Dataset: </label>
        <select id="dataset_select">
          <option class= "classdata" value="circle_dataset">Circle</option>
          <option class= "classdata" value="spiral_dataset">Spiral</option>
          <option class= "classdata" value="xor_dataset">XOR</option>
          <option class= "classdata" value="gaus_dataset">Gaussian</option>
          <option class= "reg" value="regplain">Plain</option>
          <option class= "reg" value="reggaus">Gaussian</option>
        </select><br>
        <label>Weight initialization: </label>
        <select id="weights_init_select">
          <option value="weights_random">Random values</option>
          <option value="weights_equal">All values are equal</option>
          <option value="weights_set">Prescribed values</option>
        </select><br>
        <label>Add/Remove a Network: </label>
        <button class="parameter_button" onclick="addNetwork()">+</button>
        <button class="parameter_button" onclick="removeNetwork()">-</button><br>
      
        <table id="table">
          <tr>
            <th>Layer: </th>
            <th>Input</th>
            <th>First Layer</th>
            <th>Second Layer</th>
            <th>Output</th>
          </tr>

        </table><br>
        <button onclick="startTraining2()">Train Network</button><br>
      </div>
    </div>
    <div id="graph_section" style="margin: 0 200px;">
      <p id="trainingOnData" style="margin-top:50px;"></p>
    </div>
  </div>

  <div id="explanation">
    <div style="margin:0 auto; width:30%">
      <h2 style="font-size: 200%;">How do neurons change?</h2>
      <p>
        So many charts at once, but what can you learn from them? 
        In the following, we will take a closer look at the individual charts.
       We will first explain the hyperparameters and then the charts from left to right.
      </p>
      
    <h2>Hyperparameter</h2>
    <h3>Networktype</h3>
    <p>
    There are two types of problems we can solve here. We have a classifier 
    problem where a data point belongs to exactly one class. In our two 
    dimensional data set there are the x and y coordinates, which are also 
    the input values in the network. In classification, the network must 
    return a class that has the highest probability. In regression, there 
    are no classes and an attempt is made to calculate a computed value based 
    on the available data. Therefore, there is only one output value here.
</p>
  
    <h3>Weights</h3>
  <p>
    Random values are often used because you don't know which paths the 
    network will prioritize. This means that with a bit of luck a solution 
    can be found quickly, with bad luck none. For the reproduction of networks,
     it is possible to determine the weights yourself with fixed values. 
     However, if all weights in a layer are the same, the network will struggle to learn 
     as the symmetry ensures that all values have the same input and 
     output and the network is not trained, thus all neurons remain the same except 
      for the input layerwise. </p>

    <div class="example">
      <div></figure><figure>
        <img src="img/equal_weights.png" alt="" width="250px">
        <figcaption>All weights are equal and all neurons in the first layer are equal. <br> 
        </figcaption>
      </figure></div>
    </div>
    
    <h2>Chart Explanation</h2>
   <h3>Training process</h3>
  <p>   
  In the training process, the data set is divided into training data 
  and validation data. The first is used to train the network and the
  second is used to validate the network. An iteration is called an 
  epoch. The accuracy indicates how often the label (the class to which 
  the data point belongs) was correctly recognized during the training.
  The value 1 reflects 100% correctness in the prediction. The loss 
  function is calculated from the Output Result. This allows us to 
  evaluate and compare different networks. The closer the value is 
  to 0, the closer we are to a good network. We used the meanSquaredError
  loss function, where small deviations have little influence, while 
  large deviations have a large influence. The validation value for 
  accuracy and loss indicates how well the network reacts to a data 
  set on which it has not been trained. 
  
    No accuracy is specified for regression, as there are no classes
    respectively an infinite number of classes.
  </p>
  <div class="example" style="height:400px;">

  <div class = "first" style="display:flex">
    <div> <img src="img/sucess.png" alt="" width="250px"></div>
    <div><p>
  This network seemed to train well, you might want to add a neuron, to see if that can speed up the process or remove one to see if it can still solve the problem.
</p></div>
  </div>

  <div class = "second" style="display:flex">
    <div> <img src="img/nosuccess.png" alt="" width="250px"></div>
    <div><p>This network seemed to not find an approximation function, you might want to add a neuron, to see if that can help to solve the problem.</div>
</p></div>
  </div>

  
  <h3>Influence of a Neuron</h3>
  <p>
    This chart shows you the total sum of all outgoing connections 
    of a neuron in relation to the most influential neuron in the 
    network, which amplifies the input that leads to a good output. 
    Note that the output layer has no weights and has been assigned 
    the value 0.7 for the graphical completeness of a network. 
    Furthermore, the individual edges have been omitted to provide 
    a better overview.
  
  
  </p>
  <div class="example">
    <div class = "first" style="display:flex">
      <div> <img src="img/circle_input.png" alt="" width="250px"></div>
      <div><p>Due to the independence of the coordinates in the Classification - 
        Circle problem, we expect them to be approximately the same size. Here, 
        the values are 0.28 and 0.3.
  </p></div>
    </div>
    
    
    <div class = "second" style="display:flex">
      <div> <img src="img/gaus_input.png" alt="" width="250px"></div>
      <div><p>If the coordinates are dependent as in the Classification - Gaussian
        problem, where a positive coordinate automatically has a unique 
        label, we expect different sizes. Here, the values are 0.38 and 0.88.
     </p></div>
    </div>
    
    
     <div class = "third" style="display:flex">
      <div> <img src="img/size.png" alt="" width="250px"></div>
      <div><p>Too many neurons in a subsequent layer can cause that the influence 
        and the overall weight is increasing, as the neuron weights are 
        influenced by several following neurons when adjusting its weights. In this
        example the neurons in the hidden layer look similar small and both have two 
      outgoing weights. And the training is highly dependent on the feature of the 
      input, as the output is maximised and set 1.</p></div>
    </div>
    
    
  </div>
<h3>Weight Development in First Layer</h3>
<p> This chart allows us to have a look inside the first layer. It allows us to 
  see which neurons are priorized, when they start learning, and when 
  they stop learning. </p>
  <div class="example" style="height:400px;">

    <div class = "first" style="display:flex">
      <div> <img src="img/weight_dev.png" alt="" width="250px"></div>
      <div><p>
    In this example, the network tries to maximize the output of neuron 1 and determine 
    a certain value for neuron 0.
  </p></div>
    </div>
  
    <div class = "second" style="display:flex">
      <div> <img src="img/weight_dev_2.png" alt="" width="250px"></div>
      <div><p>
        In this example, we see that the two neurons stand out, as they were stimulated 
        early, while the rest has no significant learning curve.
      </p></div>

    </div>



  <h3>Learning Rate Development per Layer</h3>
  <p> 
    The learn rate describes the difference in total weights between two epochs.
    The layers are added together and the average is calculated. If the learning 
    rate is high, the network learns more in the epoch than if it is low. The 
    learning rate increases if a learning path through the network has been found and approaches
    zero if weights do not need to be adjusted.

  </p>
  
  <div class = "second" style="display:flex">
    <div> <img src="img/lrate.png" alt="" width="250px"></div>
    <div><p>
      In this example, we can see that at epoch 10 only the input and frst layer learn. 
      All three layers have a local maximum at epoch 18. In combination with the 
      first chart, we see that the area between epoch 8 and epoch 18 is a local 
      minimum and the learn process did stagnate.
      This chart can us also show the influence on how the number of neurons in the 
      following layer influence the previous layer. This example has 2 in the 
      input layer, 4 in the second layer and 6 in the second layer.
    </p></div>

  </div>


  
  <p>
  In conclusion, a high number of neurons can accelerate the training
  process. However, this should not be too large, as the computing power 
  increases significantly in a fully connected network. Real world data is
  usually much more complex and requires larger networks. Networks that work
  on MNIST have an input of 28x28 pixels and 60,000 training samples.
</p>
    </div>
  </div>

  <script>
    let case_num = 0;
    let tests_aktiv = false;
    let testrunname =""
    let testarray = []
    let test_iterations = 100;
    let testtime =0;
    let memoryUsage=[];
    let timeInitWorker=[];
    let timeInitNetwork=[];
    let time_copy  =0
    let timer_send_end  =0
    let time_workerinitNetworkend =0
    let timer_worker_train_end =0
    let timer_learningRate_end =0
    let timer_showheatmap_end =0
    let timer_similarity_end =0
    let timer_network =0
    let timer_plot=0
    let max_heap = 0
    let average_heap = 0
    let timer_all = 0
    let timer_start = 0


    
    let workerlist = [];
    let sameWeights = 2;
    let classifier = true;
    let firstValueNeurons = [];
    let secondValueNeurons = [];
    let currentlytraining = false;
    let trainingCounterDone = 0;



    function addNetwork() {
      let networks = document.getElementById("graph_section").childElementCount;
      if (networks < 5) {
        //prepare container for graphs
        let container = document.createElement("DIV");
        container.setAttribute("id", "graph_block_" + networks)
        container.style.backgroundColor = "#eeeeee";
        container.style.height = "210px";
        container.style.display = "flex";
        container.style.padding = "auto";
        document.getElementById("graph_section").appendChild(container);
        let networkdescription = document.createElement("DIV");
        networkdescription.setAttribute("id", "networkdescription_" + networks);
        networkdescription.style.height = "210px";
        networkdescription.style.width = "110px";
        document.getElementById("graph_block_" + networks).appendChild(networkdescription);
        let networkname = document.createElement("p");
        networkname.innerText = "Network " + networks;
        networkname.style.width = "110px";
        networkname.style.margin = "60px 20px 0px 0px";
        document.getElementById("networkdescription_" + networks).appendChild(networkname);
    
        let acc_val = document.createElement("DIV");
        acc_val.setAttribute("id", "acc_val" + networks);
        acc_val.style.height = "210px";
        acc_val.style.width = "330px";
        document.getElementById("graph_block_" + networks).appendChild(acc_val);
        let network = document.createElement("DIV");
        network.setAttribute("id", "network_" + networks);
        network.style.height = "210px";
        network.style.width = "280px";
        document.getElementById("graph_block_" + networks).appendChild(network);
        let firstLayer_chart = document.createElement("DIV");
        firstLayer_chart.setAttribute("id", "firstLayer_" + networks);
        firstLayer_chart.style.height = "210px";
        firstLayer_chart.style.width = "300px";
        document.getElementById("graph_block_" + networks).appendChild(firstLayer_chart);
        let lrdgraph = document.createElement("DIV");
        lrdgraph.setAttribute("id", "lrd_" + networks);
        lrdgraph.style.height = "210px";
        lrdgraph.style.width = "300px";
        document.getElementById("graph_block_" + networks).appendChild(lrdgraph);

        let networkinformation = document.createElement("DIV");
        networkinformation.setAttribute("id", "networkinformation" + networks);
        networkinformation.style.height = "210px";
        networkinformation.style.width = "110px";
        document.getElementById("graph_block_" + networks).appendChild(networkinformation);
        let infobox = document.createElement("p");
        infobox.innerText = "Information to: ";
        infobox.style.width = "140px";
        infobox.style.margin = "auto 2px";
        document.getElementById("networkinformation" + networks).appendChild(infobox);
        let networkinfo = document.createElement("DIV");
        networkinfo.setAttribute("id", "networkinfo" + networks);
        networkinfo.style.height = "80px";
        networkinfo.style.width = "80px";
        networkinfo.style.display = "flex";
        document.getElementById("networkinformation" + networks).appendChild(networkinfo);   
        for (let i = 0; i < 4; i++){
        let networkinfoI = document.createElement("DIV");
        networkinfoI.setAttribute("id", "networkinfo" + networks + i);
        networkinfoI.setAttribute("class", "tooltip");
        networkinfoI.innerText = i+1;
        networkinfoI.style.backgroundColor = "#FFFFFF";
        networkinfoI.style.border = "1px solid #c0c0c0";
        networkinfoI.style.borderRadius = "2px";
        networkinfoI.style.width = "10px";
        networkinfoI.style.margin = "2px 2px auto auto";
        document.getElementById("networkinfo" + networks).appendChild(networkinfoI);
        let networkinfoIspan = document.createElement("p");
        networkinfoIspan.setAttribute("id", "networkinfotext" + networks + i);
        networkinfoIspan.setAttribute("class", "tooltiptext");
        networkinfoIspan.innerText = i+1;
        document.getElementById("networkinfo" + networks + i).appendChild(networkinfoIspan);
      }     
        
        //append to table
        let tr  = document.createElement("tr");
        tr.setAttribute("id", "input_tr_" + networks);
        document.getElementById("table").appendChild(tr);
        let td0  = document.createElement("td");
        let td1  = document.createElement("td");
        let td2  = document.createElement("td");
        let td3  = document.createElement("td");
        let td4  = document.createElement("td");
        td0.innerText = "Network "+ String(networks)+":";
        td1.innerHTML = 2
        td2.setAttribute("id","input1_td"+networks);
        td3.setAttribute("id","input2_td"+networks);
        td4.innerHTML = 2
        document.getElementById("input_tr_" + networks).appendChild(td0);
        document.getElementById("input_tr_" + networks).appendChild(td1);
        document.getElementById("input_tr_" + networks).appendChild(td2);
        document.getElementById("input_tr_" + networks).appendChild(td3);
        document.getElementById("input_tr_" + networks).appendChild(td4);
        let input1  = document.createElement("input");
        let input2  = document.createElement("input");
        input1.type = "number";
        input1.max = 8;
        input1.min = 1;
        input1.value = 2;
        input1.setAttribute("id", "input1_"+ networks);
        input2.type = "number";
        input2.max = 8;
        input2.min = 1;
        input2.value = 2;
        input2.setAttribute("id", "input2_"+ networks);
        document.getElementById("input1_td" + networks).appendChild(input1);
        document.getElementById("input2_td" + networks).appendChild(input2);
        eventLis("input1_" + networks, "input2_" + networks, networks,firstValueNeurons,secondValueNeurons);
        
      }
    }
    addNetwork();

    function openNav() {
      document.getElementById("mySidebar").style.width = "250px";
      document.getElementById("main").style.marginLeft = "250px";
      document.getElementById("openbutton").style.visibility = "hidden";
    }

    function closeNav() {
      document.getElementById("mySidebar").style.width = "0";
      document.getElementById("main").style.marginLeft = "0";
      document.getElementById("openbutton").style.visibility = "visible";
    }

    function closeNavAbout(){  
      $('#main').css("display", "none");
      $('#explanation').css("display", "none");
      $('#about').css("display","inline");
}
    function closeNavTraining(){
      $('#explanation').css("display", "none");
      $('#about').css("display", "none");
      $('#main').css("display","inline");
      closeNav();}
    function closeNavExplain(){
      $('#main').css("display", "none");
      $('#about').css("display", "none");
      $('#explanation').css("display","inline");

    }

    $("#dataset_select").change(function () {
      selectData(this.value)
    });


    $("#weights_init_select").change(function () {
      if (this.value == "weights_random"){
        sameWeights = 2
      }
      else if (this.value == "weights_equal"){
        sameWeights = 0
      }
      else {
        sameWeights = 1
      }

    });
    
    $("#networktype").change(function () {
      if (this.value == "classification"){
        classifier = true
        $(".reg").css("display", "none")
        $(".classdata").css("display", "inline")
        $("#dataset_select").val("circle_dataset");
      }
      else if (this.value == "regression"){
        classifier = false
        $(".classdata").css("display", "none")
        $(".reg").css("display", "inline")
        $("#dataset_select").val("regplain")
      }
      selectData($("#dataset_select").val())
    });

    function selectData(value){
    points = [];
      if (value == "circle_dataset"){
        classifyCircleData();
      }
      else if (value == "spiral_dataset"){
        spiral();
      }
      else if (value == "xor_dataset"){
        createXORData();
      }
      else if  (value == "gaus_dataset"){
        gaus();
      }
      else if  (value == "regplain"){
        regressionPlain();
      }
      else{
        regressionGaus();
      }
      drawDataPlot()
      schuffleData();
      //load new data
    }


    function eventLis(inputFirstLayer, inputSecondLayer, id,firstValueNeurons,secondValueNeurons){
      firstValueNeurons.push(2);
      secondValueNeurons.push(2);
      
    document.getElementById(inputFirstLayer).addEventListener("change", function () {
      let v = parseInt(this.value);
      if (v < 1) this.value = 1;
      if (v > 8) this.value = 8;
      firstValueNeurons[id-1]=(Number(this.value));  
    });

    document.getElementById(inputSecondLayer).addEventListener("change", function () {
      let v = parseInt(this.value);
      if (v < 1) this.value = 1;
      if (v > 8) this.value = 8;
      secondValueNeurons[id-1]=(Number(this.value)); 
    });}



    function removeNetwork() {
      if (document.getElementById("graph_section").childElementCount > 2) {
        let graphs = document.getElementById("graph_section");
        graphs.removeChild(graphs.lastChild);
        if (models != undefined){
        models.splice(document.getElementById("graph_section").childElementCount - 1, 1);}
        //remove entry in parameter_table nth-child(2)
        let table = document.getElementById("table");
        table.removeChild(table.lastChild);
      }
    }



    document.getElementById("trainingOnData").innerText = "Press \"Train Network\" to train the models.";


// DATA
//Domain[-10,10]
    //circle data
    function dist(a, b) {
      let dx = a.x - b.x;
      let dy = a.y - b.y;
      return Math.sqrt(dx * dx + dy * dy);
    }

    let points = [];
    let numSamples = 500;
    //change validation number value

    function classifyCircleData() {

      let radius = 10;

      function getCircleLabel(p, center) {
        return (dist(p, center) < (radius * 0.5)) ? 1 : 2;
      }

      // Generate positive points inside the circle.
      for (let i = 0; i < numSamples / 2; i++) {
        let r = Math.random() * radius / 2;
        let angle = Math.random() * 2 * Math.PI;
        let x = r * Math.sin(angle);
        let y = r * Math.cos(angle);
        let label = getCircleLabel({ x: x, y: y }, { x: 0, y: 0 });
        points.push({ x, y, label });
      }

      // Generate negative points outside the circle.
      for (let i = 0; i < numSamples / 2; i++) {
        let r = Math.random() * radius * 3 / 10 + radius * 13/20;
        let angle = Math.random() * 2 * Math.PI;
        let x = r * Math.sin(angle);
        let y = r * Math.cos(angle);
        let label = getCircleLabel({ x: x, y: y }, { x: 0, y: 0 });
        points.push({ x, y, label });
      }
    }

    function createXORData(){
      for (let i = 0; i < numSamples; i++) {
        let x = Math.random()*(16)-8;
        let y = Math.random()*(16)-8;
        let padding = 0.8;
        x += x > 0 ? padding : -padding;
        y += y > 0 ? padding : -padding;
        let label = x * y >= 0 ? 1 : 2;
        points.push({ x, y, label });
      }
    }

    function spiral(){
      let n = numSamples / 2;

      function genSpiral(delta, label) {
        for (let i = 0; i < n; i++) {
          let r = i / n * 9;
          let t = 1.75 * i / n * 2 * Math.PI + delta;
          let x = r * Math.sin(t);
          let y = r * Math.cos(t);
          points.push({x, y, label});
        }
      }
      genSpiral(0,1);
      genSpiral(Math.PI,2);
    }

    function gaus(){
      function normalRandom(mean = 0){
        let v1 = 0;
        let v2 = 0;
        let s = 0;
        do {
          v1 = 6 * Math.random() - 3;
          v2 = 6 * Math.random() - 3;
          s = v1 * v1 + v2 * v2;
        } while (s > 3);
        let result = Math.sqrt(-2 * Math.log((s/3)) / (s/2)) * v1;
        return mean + result;
      };
      function createGaus(cx, cy, label){
      for (let i = 0; i < numSamples / 4; i++) {
      let x = normalRandom(cx);
      let y = normalRandom(cy);
      points.push({x, y, label});
    }
  };

  createGaus(4.5, 4.5, 1); // Gaussian with positive examples.
  createGaus(-4.5, -4.5, 2);

    }

    function regressionPlain(){
      let moreSamples = numSamples*2
      for (let i = 0; i<moreSamples; i++){
        let x = Math.random()*20-10;
        let y = Math.random()*20-10;
        let label = (x+y)/20
        points.push({x, y, label})
      }
    }

    function schuffleData() {

      for (var i = points.length - 1; i > 0; i--) {
        var j = Math.floor(Math.random() * (i + 1));
        var temp = points[i];
        points[i] = points[j];
        points[j] = temp;
      }
    }
    
    function regressionGaus(){
      let gaussians = [
        [-7,4,1],
        [0,4,-1],
        [7,4,1],
        [-7,-4,-1],
        [0,-4,1],
        [7,-4,-1]
      ]
      let moreSamples = numSamples*2
      for (let i=0; i <moreSamples; i++){
        let x = Math.random()*20-10;
        let y = Math.random()*20-10;
        let label = 10
        for (let j = 0; j < 6; j++){
          let clothestPoint = gaussians[j][2]*(dist({x,y},{x:gaussians[j][0],y:gaussians[j][1]}))
          if (Math.abs(clothestPoint) < Math.abs(label)) {
            label = clothestPoint;
          }
        }
        if (label > 0 ){
          label = 1-(label/Math.sqrt(45))
        }else{
          label = -1-(label/Math.sqrt(45))
        }
        points.push({x:x, y:y, label:label})
      }
    }
    
    function drawDataPlot(){
    let dataSpec
    if ($("#networktype").val() == "classification"){
    dataSpec = {
      "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
      "description": "A simple scatter plot to display circle data.",
      "data": {
        "values": points,
      },

      "mark": "circle",
      "title":"Selected Dataset",
      "width": 140,
      "height": 140,
      "background": "#eeeeee",
      "view": {"fill": "#f9f9f9"},
      "config":{"legend":{"disable":"true"}},
      "encoding": {
        "x": { "field": "x", "type": "quantitative", "axis":{"title":"X-Value"},"scale":{"domain":[-10,10]} },
        "y": { "field": "y", "type": "quantitative", "axis":{"title":"Y-Value"},"scale":{"domain":[-10,10]} },
        "color": { "field": "label",
                    "scale": {"range":["#d95f02", "#7570b3"],
                              "domain": [1,2] },
                              "legend": {
                                        "labelExpr": "datum.label == 1 ? 'Class 1' : datum.label == '2' ? 'Class 2' : 'error'",
                                          },
                              "title":"Point of"},

        "tooltip": [{ "field": "label", "title":"Class Label" },{ "field": "x","title":"X-Value" }, { "field": "y","title":"Y-Value" }, ],
      
      
      
      },


    };}


    else{
      dataSpec= {"$schema": "https://vega.github.io/schema/vega-lite/v5.json",
      "description": "A simple scatter plot to display circle data.",
      "data": {
        "values": points,
      },

      "mark": "circle",
      "title":"Selected Dataset",
      "width": 140,
      "height": 140,
      "background": "#eeeeee",
      "view": {"fill": "#f9f9f9"},
      "encoding": {
        "x": { "field": "x", "type": "quantitative", "axis":{"title":"X-Value"},"scale":{"domain":[-10,10]} },
        "y": { "field": "y", "type": "quantitative", "axis":{"title":"Y-Value"},"scale":{"domain":[-10,10]} },
        "color": { "field": "label", "type":"quantitative", "title":"Value","scale": {
        "range": "ordinal"
      }},

        "tooltip": [{ "field": "label", "title":"Value" },{ "field": "x","title":"X-Value" }, { "field": "y","title":"Y-Value" }, ],    
      },}
    }

    vegaEmbed("#dataplot", dataSpec, {renderer: "svg", actions:false});
  }

  let trainingData = []
  let outputData = []
  function convertdata (){
    trainingData = tf.tensor2d(points.map(item => [item.x, item.y]));
    if (classifier){
    outputData = tf.tensor(points.map(item => [
      item.label == 1 ? 1 : 0,
      item.label == 2 ? 1 : 0,
    ]));}
    else{
      outputData = tf.tensor(points.map(item => [item.label]))
    }
  }
 classifyCircleData();
schuffleData();
drawDataPlot()
convertdata()

    // convert input
    // Create a Tensorflow Model
    const bias = true;
  
    async function initNetwork(model, firstLayer, secondLayer, sameWeights, classifier) {
    model = tf.sequential();

    function setinitWeights(a,b,layer){
      let weight_array = []
      for (let index_a = 0; index_a < a; index_a++){
        for (let index_b = 0; index_b < b; index_b++){
          weight_array.push((1+index_b)/b)
        }
      }
      let tensor = tf.tensor(weight_array,[a,b])
      model.layers[layer].setWeights([tensor,tf.zeros([b])])
    }

    if (classifier){
    model.add(tf.layers.dense({ inputShape: [2], useBias: true, units: firstLayer, activation: "sigmoid" }));
    model.add(tf.layers.dense({ units: secondLayer, useBias: true, activation: "sigmoid" }));
    model.add(tf.layers.dense({ units: 2, useBias: true, activation: "softmax" }));
    }else{
    model.add(tf.layers.dense({ inputShape: [2], useBias: true, units: firstLayer, activation: "tanh" }));
    model.add(tf.layers.dense({ units: secondLayer, useBias: true, activation: "tanh" }));
    model.add(tf.layers.dense({ units: 1, useBias: true, activation: "tanh" }));
    }
    if (sameWeights == 0){
      let init_weights_input = tf.fill([2, firstLayer], 0.5)
      let init_weights_first = tf.fill([firstLayer, secondLayer], 0.5)
      let init_weights_second = tf.fill([secondLayer, 2], 0.5)
      model.layers[0].setWeights([init_weights_input,tf.zeros([firstLayer])])
      model.layers[1].setWeights([init_weights_first,tf.zeros([secondLayer])])
      model.layers[2].setWeights([init_weights_second,tf.zeros([2])])
    }
    else if (sameWeights == 1){
      setinitWeights(2,firstLayer,0);
      setinitWeights(firstLayer,secondLayer,1);
      setinitWeights(secondLayer,2,2);
    }   
    
    model.compile({ loss: "meanSquaredError", optimizer: tf.train.adam(.01), metrics: ["acc"] });
    return model
  }

    async function training(model, network_index, classifier) {
      let acc = [];
      let plot3 = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "A simple scatter plot to display circle data.",
        
        "title": "Training process",
        "background": "#eeeeee",
      
        "vconcat": [{
          "view": {"fill": "#f9f9f9"},
          "width": 140,
          "height": 140,
          "data": {
            "values": acc,
          },
          "encoding": {
            "x": { "field": "epoch", "type": "quantitative", "title": "Epoch" }
          },
          "layer": [{
            "mark": "line",
            "encoding": {
              "y": { "field": "value", "type": "quantitative", "title": "Value", "scale":{"domain":[0,1]}, },
              "color":{"field":"type", "type":"nominal",
                "scale":{"range":["#33a02c","#1f78b4","#a6cee3","#b2df8a"],
                          "domain":["acc","val_acc","loss","val_loss"]},
                "legend": {"labelExpr": "datum.label == 'acc' ? 'Accuracy' :datum.label == 'loss' ? 'Loss' :datum.label == 'val_acc' ? 'Validation Accuracy' : 'Loss Validation'"
            },
            "title":"Training Values",
          }
            }
          },
          {
            "params": [{
              "name": "hover",
              "select": {
                "type": "point",
                "fields": ["epoch"],
                "nearest": true,
                "on": "pointermove",
                "clear": "pointerout"
              }
            }],
            "transform": [{ "pivot": "type", "value": "value", "groupby": ["epoch"] }],
            "mark": "rule",
            "encoding": {
              "tooltip": [{ "field": "epoch", "type": "quantitative", "title": "Epoch" },
              { "field": "acc", "type": "quantitative", "title": "Accuracy" },
              { "field": "val_acc", "type": "quantitative", "title": "Validation_Accuracy" },
              { "field": "loss", "type": "quantitative", "title": "Loss" },
              { "field": "val_loss", "type": "quantitative", "title": "Validation_Loss" }],
              "opacity": {
                "condition": { "value": 1, "param": "hover", "empty": false },
                "value": 0.0
              }
            }
          }]
        }

        ]
      }

      async function learningRateDecay( prevLayer, input, firstLayer, secondLayer){
  function diff(prevLayer, actLayer){
    let lRateDecay = 0;
    for (let i = 0; i< actLayer.length; i++){
      for (let j = 0;j<actLayer[0].length;j++){
      lRateDecay += Math.abs(prevLayer[i][j]-actLayer[i][j]);
    }}
    return (lRateDecay/actLayer.length)
  }
  let layer_input = diff(prevLayer[0], input);
  let layer_H1 =diff(prevLayer[1], firstLayer);
  let layer_H2 =diff(prevLayer[2], secondLayer);
  return [layer_input < 0.6?layer_input:0.6,layer_H1< 0.6?layer_H1:0.6,layer_H2< 0.6?layer_H2:0.6]

}

async function showheatmap(id, input, firstLayer, secondLayer, classifier){
  let data_weights = []; 
  let all_weights = [input, firstLayer, secondLayer]
  let layer_name =""
  let max_node_weight  = 0 
  for (let layer = 0; layer < 3; layer++){
    let number_neurons = all_weights[layer].length;
    for (let neuron = 0; neuron < number_neurons; neuron++){
      let weights = all_weights[layer][neuron].length;
      let weight_sum = 0;
      for (let weight = 0; weight < weights; weight++){
        weight_sum += Math.abs(all_weights[layer][neuron][weight]);
      } 
      if (weight_sum > max_node_weight){max_node_weight = weight_sum}
    } 
  }
  for (let layer = 0; layer < 3; layer++){
    if (layer == 0){ layer_name = "Input Layer"}
    else if (layer == 1){layer_name ="First Layer"}
    else if (layer == 2){layer_name ="Second Layer"}
    let number_neurons = all_weights[layer].length;
    for (let neuron = 0; neuron < number_neurons; neuron++){
      let weights = all_weights[layer][neuron].length;
      let weight_sum = 0;
      for (let weight = 0; weight < weights; weight++){
        weight_sum += Math.abs(all_weights[layer][neuron][weight]);
      }
      let scaled_weight_sum = weight_sum/max_node_weight
      let yposition = ((neuron+1)/(number_neurons+1));
      data_weights.push({"layer":layer_name,"yposition":yposition, "weight":scaled_weight_sum,"neuron":neuron})
    }

  }
  if (classifier){
  data_weights.push({"layer":"Output Layer","yposition":0.33, "weight":0.7,"neuron":0});
  data_weights.push({"layer":"Output Layer","yposition":0.67, "weight":0.7,"neuron":1});}
  else{
    data_weights.push({"layer":"Output Layer","yposition":0.5, "weight":0.7,"neuron":0});
  }
  plot_heat(id, data_weights)

}

function pushWeightsLayer1(firstLayer,epoch){
  for (let i = 0; i< firstLayer.length; i++){
    let neuronName = "Neuron "+i
    let sum = 0
    for (let j = 0; j < firstLayer[i].length; j++){
      sum += Math.abs(firstLayer[i][j])
    }
    weights_layer1.push({epoch:epoch, neuron:neuronName, value:sum})
  }
}
async function similarity(id, layers){
function sort_dissimilarity_revers(d2array) {
  let minimum = d2array[0].length * 2;
  let clothesthneighbour = 1;
  let d2arraylen = d2array.length;
  let d2outarraylen = d2array[0].length;
  let reverse = false;
  for (let outarray = 1; outarray < d2arraylen; outarray++) {
    let euklidsum = 0;
    let euklidsum_revers = 0;
    for (let inarray = 0; inarray < d2outarraylen; inarray++) {
      euklidsum += Math.abs(d2array[0][inarray] - d2array[outarray][inarray]);
      euklidsum_revers += Math.abs(d2array[0][inarray] + d2array[outarray][inarray]);
    }
    if (euklidsum < euklidsum_revers) {
      if (euklidsum < minimum) {
        minimum = euklidsum;
        clothesthneighbour = outarray;
        reverse = false;
      }
    }
    else if (euklidsum_revers < minimum) {
      minimum = euklidsum_revers;
      clothesthneighbour = outarray;
      reverse = true;
    }
  }
  let scaled_minimum = Math.floor(10*(1-(minimum/d2outarraylen)))/10
  return [clothesthneighbour, reverse, scaled_minimum.toString()]
}



function scaleData(predata){
//scale down to 1max
//create 1D array with max/min
let maxRow = predata.map(function (row) { return Math.max.apply(Math, row); });
let minRow = predata.map(function (row) { return Math.min.apply(Math, row); });
let max_row_length = maxRow.length;
var scaleddata = [];
//scale with Math.max(maxRow, Math.abs(minRow))
for (let i = 0; i < max_row_length; i++) {
  if (Math.abs(maxRow[i]) > Math.abs(minRow[i])) {
    var scale = Math.abs(maxRow[i]);
  }
  else {
    var scale = Math.abs(minRow[i]);
  }
  var helper = predata[i].map(x => x / scale);
  scaleddata.push(helper);
}
return scaleddata
}

let similarity_array = []
for (let i = 0; i < layers.length; i++){
let switched_signs = scaleData(layers[i]);
let iterations = switched_signs.length - 1;
for (let index = 0; index < iterations; index++) {
  var result = sort_dissimilarity_revers(switched_signs.slice(index, switched_signs.length));
  if (result[0] != 1) {
    let rowhelper3 = switched_signs[result[0] + index];
    switched_signs[result[0] + index] = switched_signs[index + 1];
    switched_signs[index + 1] = rowhelper3;
  }
  if (result[1]) {
    switched_signs[index + 1] = await switched_signs[index + 1].map(el => -el);
  }
  similarity_array.push({"layerID":i, "similarity":result[2]});
}
}
plot_similarity(id, similarity_array)
}

      let learningRate = [];
      let prevLayer = [await model.getWeights()[0].array(), await model.getWeights()[2].array(), await model.getWeights()[4].array()]
      let weights_layer1 = []
      let networkID = document.getElementById("acc_val" + (network_index + 1));
    const startTime = Date.now();
      const h = await model.fit(trainingData, outputData, {
        epochs: 52,
        //shuffle:true,
        validationSplit: 0.2,
        callbacks: [{
          onEpochEnd: async (epoch, logs) => {
            let input = await model.getWeights()[0].array()
        let firstLayer = await model.getWeights()[2].array()
        let secondLayer = await model.getWeights()[4].array()
        if (classifier){
          pushWeightsLayer1(firstLayer,epoch);
          acc.push({ epoch: epoch, value: logs.val_loss, type: "val_loss" });
        acc.push({ epoch: epoch, value: logs.loss, type: "loss" });
        acc.push({ epoch: epoch, value: logs.val_acc, type: "val_acc" });
        acc.push({ epoch: epoch, value: logs.acc, type: "acc" });
      }else{
      acc.push({ epoch: epoch, value: logs.val_loss < 0.6? logs.val_loss: 0.6, type: "val_loss" });
      acc.push({ epoch: epoch, value: logs.loss < 0.6? logs.loss: 0.6, type: "loss" });
    }

        learningRate_values = await learningRateDecay( prevLayer, input, firstLayer, secondLayer)
        learningRate.push({epoch:epoch, value:learningRate_values[0], type:"input"})
        learningRate.push({epoch:epoch, value:learningRate_values[1], type:"hidden1"})
        learningRate.push({epoch:epoch, value:learningRate_values[2], type:"hidden2"})
        prevLayer = [input, firstLayer, secondLayer]

        if (epoch%2==0){
        plot_training(network_index, acc)
        plot_lrd(network_index, learningRate)
        plot_firstLayer(network_index, weights_layer1)
        }
        if (epoch%10 == 0){
          showheatmap(network_index, input, firstLayer, secondLayer, classifier)

          similarity(network_index, [input, firstLayer, secondLayer])
        }
        }
        },
          //callback
        ]
      });

    }


    function plot_training(id, acc){
      let timer_plot_start = performance.now()
      let networkID = document.getElementById("acc_val"+(id+1));
      let plot3

      if ($("#networktype").val() == "classification"){
      plot3 = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "Display of trainingsprocess.",
        "background": "#eeeeee",
        "config":{"legend":{"disable":"true"}},
        "title": "Training process",
        
        "vconcat": [{
          "view": {"fill": "#f9f9f9"},
          "width": 140,
          "height": 140,
          "data": {
            "values": acc,
          },
          "encoding": {
            "x": { "field": "epoch", "type": "quantitative", "title": "Epoch" }
          },
          "layer": [{
            "mark": "line",
            "encoding": {
              "y": { "field": "value", "type": "quantitative", "title": "Value", "scale":{"domain":[0,1]}, },
              "color":{"field":"type", "type":"nominal",
                "scale":{"range":["#33a02c","#1f78b4","#a6cee3","#b2df8a"],
                          "domain":["acc","val_acc","loss","val_loss"]},
                          "legend": {"labelExpr": "datum.label == 'acc' ? 'Accuracy' :datum.label == 'loss' ? 'Loss' :datum.label == 'val_acc' ? 'Validation Accuracy' : 'Loss Validation'"
            },
            "title":"Training Values",
          }

            }
          },
          {
            "params": [{
              "name": "hover",
              "select": {
                "type": "point",
                "fields": ["epoch"],
                "nearest": true,
                "on": "pointermove",
                "clear": "pointerout"
              }
            }],
            "transform": [{ "pivot": "type", "value": "value", "groupby": ["epoch"] }],
            "mark": "rule",
            "encoding": {
              "tooltip": [{ "field": "epoch", "type": "quantitative", "title": "Epoch" },
              { "field": "acc", "type": "quantitative", "title": "Accuracy" },
              { "field": "val_acc", "type": "quantitative", "title": "Validation_Accuracy" },
              { "field": "loss", "type": "quantitative", "title": "Loss" },
              { "field": "val_loss", "type": "quantitative", "title": "Validation_Loss" }],
              "opacity": {
                "condition": { "value": 1, "param": "hover", "empty": false },
                "value": 0.0
              }
            }
          }]
        }

        ]
      }
    }
      else{
        plot3 = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "A simple scatter plot to display circle data.",
        "background": "#eeeeee",
      
        "title": "Training process",
        "vconcat": [{
          "view": {"fill": "#f9f9f9"},
          "width": 140,
          "height": 140,
          "data": {
            "values": acc,
          },
          "encoding": {
            "x": { "field": "epoch", "type": "quantitative", "title": "Epoch" }
          },
          "layer": [{
            "mark": "line",
            "encoding": {
              "y": { "field": "value", "type": "quantitative", "title": "Value", "scale":{"domain":[0,0.7]}, },
              "color":{"field":"type", "type":"nominal",
                "scale":{"range":["#33a02c","#1f78b4"],
                          "domain":["loss","val_loss"]},
                "legend": {"labelExpr": "datum.label == 'loss' ? 'Loss' : 'Loss Validation'"    
              },
            "title":"Training Values",
          }
            }
          },
          {
            "params": [{
              "name": "hover",
              "select": {
                "type": "point",
                "fields": ["epoch"],
                "nearest": true,
                "on": "pointermove",
                "clear": "pointerout"
              }
            }],
            "transform": [{ "pivot": "type", "value": "value", "groupby": ["epoch"] }],
            "mark": "rule",
            "encoding": {
              "tooltip": [{ "field": "epoch", "type": "quantitative", "title": "Epoch" },
              { "field": "loss", "type": "quantitative", "title": "Loss" },
              { "field": "val_loss", "type": "quantitative", "title": "Validation_Loss" }],
              "opacity": {
                "condition": { "value": 1, "param": "hover", "empty": false },
                "value": 0.0
              }
            }
          }]
        }

        ]
      }
      

    }
      vegaEmbed(networkID, plot3, {renderer: "svg", actions:false});
      timer_plot += (performance.now()-timer_plot_start)/test_iterations
    }
  //}

    //function plot_heat(networks, data_weights, epoch){
    function plot_heat(id, data_weights){
    //for (let i = 0; i < networks; i++){
    let timer_plot_start = performance.now()
    let networkIDheatmap = document.getElementById("network_" + (id + 1));
    let plotheatmap = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "Displaying the Weights of Nodes",
        "background": "#eeeeee",
      "view": {"fill": "#f9f9f9"},
        "title": "Influence of a Neuron",

          "width": 140,
          "height": 140,
          "data": {
            "values": data_weights,
          },
          "encoding": {
            "x": { 
              "field": "layer", 
              "type": "ordinal",
              "axis": { "title":"","labelAngle":25},
              "sort":["Input Layer","First Layer","Second Layer","Output Layer"] },
            "y": { 
              "field": "yposition", 
              "type": "quantitative",
              "axis": {
                "ticks": false,
                "labels":false,
                "title":"",
                },
              "scale":{"domain":[1,0]},
              },
            "size":{
              "field":"weight",
              "type":"quantitative",
              "title":"Influence of a Neuron"
            },
            "tooltip":[
              {"field":"layer", "type":"ordinal", "title":"Layer"},
              {"field":"neuron", "type":"qualitative", "title":"Neuron"},
              {"field":"weight", "type":"qualitative", "title":"Weight"}
            ]
          },
            "mark": "circle",
            "config": {"axis": {"grid": false}}
            }
            vegaEmbed(networkIDheatmap, plotheatmap, {renderer: "svg", actions:false});
            timer_plot += (performance.now()-timer_plot_start)/test_iterations

  }

  function plot_lrd(id, lrd){
    let timer_plot_start = performance.now()
      let networkID = document.getElementById("lrd_"+(id+1));
      let lrdplot = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "A simple scatter plot to display circle data.",
        "background": "#eeeeee",
        
        "title": "Learning Rate Development per Layer",
        "vconcat": [{
          "view": {"fill": "#f9f9f9"},
          "width": 140,
          "height": 140,
          "data": {
            "values": lrd,
          },
          "encoding": {
            "x": { "field": "epoch", "type": "quantitative", "title": "Epoch" }
          },
          "layer": [{
            "mark": "line",
            "encoding": {
              "y": { "field": "value", "type": "quantitative", "title": "Learning Rate", "scale":{"domain":[0,0.7]}, },
              "color":{"field":"type", "type":"nominal",
                "scale":{"range":["#7570b3","#d95f02","#a6cee3","#1b9377"],
                          "domain":["input","hidden1","hidden2"]},
                "legend": {"labelExpr": "datum.label == 'input' ? 'Input Layer' :datum.label == 'hidden1' ? 'First Layer' : 'Second Layer'"
            },
            "title":"Layer",
          }
            }
          },
          {
            "params": [{
              "name": "hover",
              "select": {
                "type": "point",
                "fields": ["epoch"],
                "nearest": true,
                "on": "pointermove",
                "clear": "pointerout"
              }
            }],
            "transform": [{ "pivot": "type", "value": "value", "groupby": ["epoch"] }],
            "mark": "rule",
            "encoding": {
              "tooltip": [{ "field": "epoch", "type": "quantitative", "title": "Epoch" },
              { "field": "input", "type": "quantitative", "title": "Input Layer" },
              { "field": "hidden1", "type": "quantitative", "title": "First Layer" },
              { "field": "hidden2", "type": "quantitative", "title": "Second Layer" },],
              "opacity": {
                "condition": { "value": 1, "param": "hover", "empty": false },
                "value": 0.0
              }
            }
          }]
        }

        ]
      }
      vegaEmbed(networkID, lrdplot, {renderer: "svg", actions:false});
      timer_plot += (performance.now()-timer_plot_start)/test_iterations
    }



    function plot_firstLayer(id, firstLayer){
      let timer_plot_start = performance.now()
      let networkID = document.getElementById("firstLayer_"+(id+1));
      let num_first_layer_neuron = Number($("#input1_"+(id+1)).val());
      let tooltips = [{ "field": "epoch", "type": "quantitative", "title": "Epoch" }]
      for (let i = 0; i < num_first_layer_neuron; i++){
        tooltips.push({"field":"Neuron "+i, "type":"quantitative","title":"Neuron "+i})
      }

      let plorfirstLayer_chart= {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "A simple scatter plot to display circle data.",
        "background": "#eeeeee",
        
        "title": "Weight Development in First Layer",
          "view": {"fill": "#f9f9f9"},
          "width": 140,
          "height": 140,
          "data": {
            "values": firstLayer,
          },  
          "encoding": {
            "x": { "field": "epoch", "type": "quantitative", "title": "Epoch" },
          },
          "layer":[{
            "mark": "line",
            "encoding":{
            "y": { "field": "value", "type": "quantitative", "title": "Weight of Neuron", },
              "color":{"field":"neuron", "type":"nominal", "title": "Neuron"
              }}},
              {
            "params": [{
              "name": "hover",
              "select": {
                "type": "point",
                "fields": ["epoch"],
                "nearest": true,
                "on": "pointermove",
                "clear": "pointerout"
              }
            }],
            "transform": [{ "pivot": "neuron", "value": "value", "groupby": ["epoch"] }],
            "mark": "rule",
            "encoding": {
              "tooltip": tooltips,
              "opacity": {
                "condition": { "value": 1, "param": "hover", "empty": false },
                "value": 0.0
              }
            }
          }
            
            ]
            
          

      }

      vegaEmbed(networkID, plorfirstLayer_chart, {renderer: "svg", actions:false});
      timer_plot += (performance.now()-timer_plot_start)/test_iterations
    }

    function add_tooltips(id, tooltip_array){
      for (let i in tooltip_array){
      //$("#networkinfotext"+ (id+1)+i).text(tooltip_array[i])
      document.getElementById("networkinfotext"+ (id+1)+i).innerHTML =tooltip_array[i]
      }
    }

    function training_done(){
      trainingCounterDone++
      if (document.getElementById("graph_section").childElementCount-1 == trainingCounterDone){
      document.getElementById("trainingOnData").innerText = "The training has finished.";
      trainingCounterDone = 0
      currentlytraining = false
      }
    }

    //check if the smallest dataset got new elements
    function checkForEpoch(array, id){
      for (let i = 0; i < array.length; i++){
        if (array[i].length > array[id].length){
          return false
        }
      }
      return true
    }

    //Worker --allow-file-access-from-files
    async function initWorker(networks){
      let acc = [];
      let heat = [];
      for (let i = 0 ; i < networks; i++){
        acc.push([]);
        heat.push([]);
      }
      for (let i = 0; i<4; i++){
        const worker = await new Worker("worker.js");
        worker.addEventListener("message", function handleMessageFromWorker(msg){
          switch(msg.data[1]){
          case "acc":
              plot_training(msg.data[0], msg.data[2]);
              break;
          
          case "heatmap":
              plot_heat(msg.data[0], msg.data[2]);
              heap()
              break;

          case "lrd":
              plot_lrd(msg.data[0], msg.data[2]);
              break;
          
          case "similarity":
            plot_similarity(msg.data[0], msg.data[2])
            break;
          case "firstLayer":
            plot_firstLayer(msg.data[0], msg.data[2])
            break;

          case "tooltip":
            add_tooltips(msg.data[0], msg.data[2])  

          case "measurments":
            time_copy += msg.data[2][0]/test_iterations
            timer_send_end += msg.data[2][1]/test_iterations
            time_workerinitNetworkend+= msg.data[2][2]/test_iterations
            timer_worker_train_end+= msg.data[2][3]/test_iterations
            timer_learningRate_end+= msg.data[2][4]/test_iterations
            timer_showheatmap_end+= msg.data[2][5]/test_iterations
            timer_similarity_end+= msg.data[2][6]/test_iterations
            timer_network+= msg.data[2][7]/test_iterations
            break;

          case "done":
            if (tests_aktiv){
              training_done2_test()
            }
            else{
            training_done()
          }
          break;
        }
      })
        workerlist.push(worker)
      }
      return workerlist
    }

    async function startTraining2(){
      let networks = document.getElementById("graph_section").childElementCount - 1;
      if (workerlist.length == 0){workerlist = await initWorker(networks)}

      if (!currentlytraining){
    currentlytraining = true;
    document.getElementById("trainingOnData").innerText = "The training has started!";
    for (let j = 0; j < networks; j++) {
      workerlist[j].postMessage({id:j, firstLayer:firstValueNeurons[j], secondLayer:secondValueNeurons[j], sameWeights:sameWeights, data:points, classifier:classifier})     
    }
  }
    }


    var models;
    var model_training;


    //let prediction = model.predict(tf.tensor2d([[150.0,150.0],[0,0],[10,10],[100,100],[20,-100]]));

//ctr + r, chrome --enable-precise-memory-info
//https://jsfiddle.net/asmgdb06/
//Application Test
let timeInitWorker_start
let timeInitWorker_End
let start 
let training_elements  =0;

async function startTraining2_test(firstValueNeurons, secondValueNeurons, num_net){
  training_elements = num_net  
  timeInitWorker_start = performance.now()
      if (workerlist.length == 0){workerlist = await initWorker(num_net)}
    timeInitWorker_End = performance.now()-timeInitWorker_start
    //push(timeInitWorker_End)
    for (let j = 0; j < num_net; j++) {
      workerlist[j].postMessage({id:j, firstLayer:firstValueNeurons[j], secondLayer:secondValueNeurons[j], sameWeights:sameWeights, data:points, classifier:classifier})     
    }
  }

async function training_done2_test(){
      trainingCounterDone++
      if (training_elements == trainingCounterDone){
      trainingCounterDone = 0
      uJSHS = window.performance.memory.usedJSHeapSize;
      let end = performance.now();
      memoryUsage.push(uJSHS);
      testtime = end-start;
      testarray[case_num] += 1;
      let [firstValueNeurons, secondValueNeurons, num_net] = await changeInputClassification(testarray)
      
    if (firstValueNeurons == 0){
        store_eval()
      }
    else {
      startTraining2_test(firstValueNeurons, secondValueNeurons, num_net)
    }
  }
  }

function heap(){
  let heapsize = window.performance.memory.usedJSHeapSize
  if (heapsize > max_heap){
    max_heap = heapsize
  }
  average_heap += heapsize/(test_iterations*6*training_elements)
  //6 = 0,10,20,30,40,50
}
function resetValues(){  

  testtime=0
  memoryUsage=[]
  timeInitWorker=[]
  timeInitNetwork = []
  time_copy  =0
    timer_send_end  =0
    time_workerinitNetworkend =0
    timer_worker_train_end =0
    timer_learningRate_end =0
    timer_showheatmap_end =0
    timer_similarity_end =0
    timer_network =0
    timer_plot=0
    average_heap =0
    max_heap = 0

  }



let test_case = 0;
let parallel = false;
async function getTestResults() {
  tests_aktiv = true;
  testarray = [0,0,0,0]
  case_num = 0
  resetValues()

  if (test_case==0){
  testrunname = "Classification_SingleThread"
  classifier = true
  getTestResultsRec(array = [0,0,0,0])}

  //if (test_case==1){
  //testrunname = "Regression_SingleThread"
  //classifier = false
 // selectData("regplain")
  //convertdata()
  //getTestResultsRec(array = [0,0,0,0])}

  //if (test_case==2){
  //parallel = true
  //selectData("circle_dataset")
  //testrunname = "Classification_MultiThread"
  //classifier = true
  //startTraining2_test([2], [2], 1)}

  //if (test_case==3){
  //  parallel = true
  //selectData("regplain")
  //testrunname = "Regression_MultiThread"
  //classifier = false
  //startTraining2_test([2], [2], 1)
//}
}

  async function changeInputClassification(testarray){
    if (testarray[0]<test_iterations){
    let [firstValueNeurons, secondValueNeurons] = [[2], [2]];
      return [firstValueNeurons, secondValueNeurons,1]
  }
  if (testarray[0]==test_iterations){
    console.log(testtime/test_iterations)
    case_num++
    testarray[0]++
    store_eval(0)
    
    testtime = 0
  }

  if(testarray[1]<test_iterations){
    let [firstValueNeurons, secondValueNeurons] = [[8], [8]];
    return [firstValueNeurons, secondValueNeurons,1]
  }
  if (testarray[1]==test_iterations){
    console.log(testtime/test_iterations)
    store_eval(1)
    case_num++
    testarray[1]++
    
    testtime = 0
  addNetwork();
  addNetwork();
  addNetwork();
  window.scrollTo(0, document.body.scrollHeight);
}

  if(testarray[2]<test_iterations){
    let [firstValueNeurons, secondValueNeurons] = [[2,2,2,2], [2,2,2,2]];
    return [firstValueNeurons, secondValueNeurons,4]
  }
  if (testarray[2]==test_iterations){
    console.log(testtime/test_iterations)
    store_eval(2)
    
    testtime = 0
    case_num++
    testarray[2]++}

  if(testarray[3]<test_iterations){
    let [firstValueNeurons, secondValueNeurons] = [[8,8,8,8], [8,8,8,8]];
    return [firstValueNeurons, secondValueNeurons,4]
  }
  console.log(testtime/test_iterations)
  store_eval(3)
  test_case++
getTestResults(test_case)

}
 
  async function getTestResultsRec(testarray) {
    
    [firstValueNeurons, secondValueNeurons, num_net] = await changeInputClassification(testarray)
    let start = performance.now();
    document.getElementById("trainingOnData").innerText = "The training has started!";
    model_training=[];
    models = [];
    let inittime= 0
    for (let j = 0; j < num_net; j++) {
      let time_init_network_start = performance.now()
      let model = await initNetwork(models[j], firstValueNeurons[j], secondValueNeurons[j], 2, classifier);
      models.push(model);    
      let time_init_network_end = performance.now() - time_init_network_start
      inittime += time_init_network_end 
    }
    timeInitNetwork.push(inittime/num_net)
    let time_start_network_training = performance.now()
    for (let j = 0; j < num_net; j++) {
    model_training.push(new Promise((resolve, reject) => {resolve(training(models[j], j, classifier))}));
    }

    Promise.all(model_training).then(() => {
      document.getElementById("trainingOnData").innerText = "The trainings process is done!";
      uJSHS = window.performance.memory.usedJSHeapSize;}).then(()=>{
      let end = performance.now();
      //push("time":,"ram":, "case_number:")
      //memoryUsage.push({"ram":uJSHS, "time":end-start,"case_number":case_num});
      memoryUsage.push(uJSHS);
      testtime += end-start;

      //push.
      testarray[case_num] += 1;
      getTestResultsRec(testarray)
    }) 
  

}

function store_eval(neuronNum){
//  let timeName = testrunname + "_Time"
//  let memoryUsageName = testrunname + "_memoryUsage"

//localStorage.setItem(timeName, JSON.stringify(testtime));
//localStorage.setItem(memoryUsageName, JSON.stringify(memoryUsage));

//console.log(timeName, memoryUsageName)
console.log("Testrun done")
let result_storage = 
  [
  test_case,
  time_copy,
  timer_send_end,
  time_workerinitNetworkend,
  timer_worker_train_end,//all
  timer_learningRate_end,
  timer_showheatmap_end,
  timer_similarity_end,
  timer_network, 
  timer_plot,
  max_heap,
  average_heap,
  testtime,
  ]
  let storage_name = String(test_case) + String(neuronNum)
localStorage.setItem(storage_name, JSON.stringify(result_storage));
resetValues()
//jsheap: sum(every 10/5)

}

function showTestResults(){
  //console.log(JSON.parse(localStorage.getItem("testtime")))
  //console.log("memoryUsage "+JSON.parse(localStorage.getItem("memoryUsage")))
  
  console.log("20: "+JSON.parse(localStorage.getItem(20)))
  console.log("21: "+JSON.parse(localStorage.getItem(21)))
  console.log("22: "+JSON.parse(localStorage.getItem(22)))
  console.log("23: "+JSON.parse(localStorage.getItem(23)))
//Regression_SingleThread_Time
//Regression_SingleThread_memoryUsage
}


  </script>


</body>

</html>