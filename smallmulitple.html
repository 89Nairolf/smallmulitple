<!DOCTYPE html>
<html>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/vega@5"></script>
<script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script>
<script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@1.5.1/dist/tfjs-vis.umd.min.js"></script>

<style>
  body{
    background-color: #eeeeee;
  }
  p{font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif}
  td, th {
  border: 1px solid #c0c0c0;
  text-align: left;
  padding: 5px;
}
tr:nth-child(even) {
  background-color: #cacaca;
}
option:hover{
  cursor: pointer;
}
  .sidebar {
    height: 100%;
    width: 0;
    position: fixed;
    z-index: 1;
    top: 0;
    left: 0;
    background-color: #111;
    overflow-x: hidden;
    transition: 0.5s;
    padding-top: 60px;
  }

  .sidebar a {
    padding: 8px 8px 8px 32px;
    text-decoration: none;
    font-size: 25px;
    color: #818181;
    display: block;
    transition: 0.3s;
  }

  .sidebar a:hover {
    color: #f1f1f1;
  }
  .closebtn{
    margin-top: 680px;
  }
  .openbtn {
    font-size: 20px;
    cursor: pointer;
    background-color: #111;
    color: white;
    padding: 10px 15px;
    border: none;
    position: fixed;
    /*display: none;*/
  }

  .openbtn:hover {
    background-color: #444;
  }

  .reg {display:none;}
  .parameter_button{
    cursor: pointer;
    background-color: #ffffff;
    border-color: #cacaca;
  }
  #main {
    transition: margin-left .5s;
    padding: 16px;
  }
  #explanation{
    display: none;
  }
  #about{
    display: none;
  }
  @media screen and (max-height: 450px) {
    .sidebar {
      padding-top: 15px;
    }

    .sidebar a {
      font-size: 18px;
    }
  }
 p{font-size: 18px;}
  #parameterdiv {
    background-color: #eeeeee;
  }
</style>

<body>

  <div id="mySidebar" class="sidebar">
    <a href="javascript:void(0)" onclick="closeNavAbout()">About</a>
    <a href="javascript:void(0)" onclick="closeNavTraining()">Training</a>
    <a href="javascript:void(0)" onclick="closeNavExplain()">Explanation</a>
    <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a>
  </div>
  <div id="stats"></div>
  <button class="openbtn" id="openbutton" onclick="openNav()" style="font-size: 90%;">☰ Open Sidebar</button>
  <button id="openbutton" onclick="getTestResults()" style="font-size: 90%;">Tests</button>
  <button id="openbutton" onclick="showTestResults(testtime,memoryUsage)" style="font-size: 90%;">ShowTests</button>
  
  <div id="about">
    <div style="margin:auto; width:30%;">
    <h2 style="font-size: 200%;">How many Neurons do I need?</h2>
    <p>
      You've probably already heard of artificial intelligence. It is already being used
      everywhere. In weather forecasting, in autonomous cars, in image processing, in 
      medicine, in research and much more. The algorithms often remain hidden from us.
      Now, with Chat GPT from OpenAI, an interface has been created that allows anyone 
      to experience live interaction with an AI. But what exactly is an AI? This type
      of intelligence describes the ability to act appropriately and proactively, to 
      perceive sensory impressions and to react to them. The aim is to imitate human
      behavior that learns from data. This involves so-called neurons that are 
      connected to each other. By adding data, training and evaluating right or 
      wrong, the connections (also known as weights) of the neurons are strengthened 
      or weakened. The algorithm is often presented as a black box model where the 
      user does not know how the training actually works. We want to change that!
</p>
      <h3>
        From the black box to the white box model
      </h3>
<p>
  Efforts have been underway for some time to make AI and neural networks more 
  accessible to the general public. Tensorflow Playground is one such tool, which
   was released in 2013. It allows you to train your own network on a data set 
   and see the weights of the connections as well as how the node splits the data! 
   Cool, right?<br>
  Some parameters are not learned by the network and must be determined before 
  training, the so-called hyperparameters. There are 2<sup>n</sup> possible constellations,
   with n as the number of hyperparameters. With Tensorflow Playground, you can 
   set a lot of parameters without being directly aware of the effects.
</p>
<h3>How many Neurons do I need?</h3>
<p>
  We deal with this question. Does more always help more? And how does this affect
   training? In the <a href="javascript:void(0)" onclick="closeNavTraining()" >Training section</a>,
    inside the sidebar, you have the opportunity to create 
   your own network. We stay close to the Tensorflow Playground model, limit the
    selection of hyperparameters and provide you with a small multiple so that you
     can get information about the effects as well as the possibility to compare 
     it with similar networks. A more detailed explanation of the individual 
     graphics can be found in the <a href="javascript:void(0)" onclick="closeNavExplain()" >Analysis section</a>.
    </p>

  </div>
  </div>
  
  <div id="main">
    <h2 style="margin-left:350px; font-size: 200%;">How many Neurons do I need?</h2>
    
    <div id="parameterdiv" style="display: flex; margin: 0px 0px 0px 150px;">
      <div id="dataplot" style="height:200px; width: 250px; margin-right:50px"></div>
      <div id="parameters">
        <label>Type of Network: </label>
        <select id="networktype">
          <option value="classification">Classification</option>
          <option value="regression">Regression</option>
        </select><br>
        
        <label>Selected Dataset: </label>
        <select id="dataset_select">
          <option class= "classdata" value="circle_dataset">Circle</option>
          <option class= "classdata" value="spiral_dataset">Spiral</option>
          <option class= "classdata" value="xor_dataset">XOR</option>
          <option class= "classdata" value="gaus_dataset">Gaussian</option>
          <option class= "reg" value="regplain">Plain</option>
          <option class= "reg" value="reggaus">Gaussian</option>
        </select><br>
        <label>Weight initialization: </label>
        <select id="weights_init_select">
          <option value="weights_random">Random values</option>
          <option value="weights_equal">All values are equal</option>
          <option value="weights_set">Prescribed values</option>
        </select><br>
        <label>Add/Remove Number of Networks: </label>
        <button class="parameter_button" onclick="addNetwork()">+</button>
        <button class="parameter_button" onclick="removeNetwork()">-</button><br>
      
        <table id="table">
          <tr>
            <th>Layer: </th>
            <th>Input</th>
            <th>Hidden One</th>
            <th>Hidden Two</th>
            <th>Output</th>
          </tr>

        </table><br>
        <button onclick="startTraining2()">Train Network</button><br>
      </div>
    </div>
    <div id="graph_section" style="margin: 0 200px;">
      <p id="trainingOnData" style="margin-top:50px;"></p>
    </div>
  </div>

  <div id="explanation">
    <div style="margin:0 auto; width:30%">
      <h2 style="font-size: 200%;">How many Neurons do I need?</h2>
      <p>
        So many charts at once, but what can you learn from them? 
        In the following, we will take a closer look at the individual charts.
       We will first explain the hyperparameters and then the charts from left to right.
      </p>
      
    <h2>Hyperparameter</h2>
    <h3>Networktype</h3>
    <p>
    There are two types of problems we can solve here. We have a classifier 
    problem where a data point belongs to exactly one class. In our two 
    dimensional data set there are the x and y coordinates, which are also 
    the input values in the network. In classification, the network must 
    output a class that has the highest probability. In regression, there 
    are no classes and an attempt is made to calculate a computed value based 
    on the available data. Therefore, there is only one output value here.
</p>
    <div class="example">
      Classification,
      Regression,
  
    </div>
  
    <h3>Weights</h3>
  <p>
    Random values are often used because you don't know which paths the 
    network will prioritize. This means that with a bit of luck a solution 
    can be found quickly, with bad luck none. For the reproduction of networks,
     it is possible to determine the weights yourself with fixed values. 
     However, if all values are the same, the network will not improve the
      symmetry ensures that all values have the same input and output and 
      the network is not trained, thus all neurons remain the same except 
      for the input layerwise. </p>

    <div class="example">
      Random, one good, one bad
      All equal - weights of Neurons, Pariwise similarity
    </div>
    
    <h2>Chart Explanation</h2>
   <h3>Training process</h3>
  <p>   
  In the training process, the data set is divided into training data 
  and validation data. The first is used to train the network and the
  second is used to validate the network. An iteration is called an 
  epoch. The accuracy indicates how often the label (the class to which 
  the data point belongs) was correctly recognized during the training.
  The value 1 reflects 100% correctness in the prediction. The loss 
  function is calculated from the Output Result. This allows us to 
  evaluate and compare different networks. The closer the value is 
  to 0, the closer we are to a good network. We used the meanSquaredError
  loss function, where small deviations have little influence, while 
  large deviations have a large influence. The validation value for 
  accuracy and loss indicates how well the network reacts to a data 
  set on which it has not been trained. 
  
    No accuracy is specified for regression, as there are no classes
    respectively an infinite number of classes.
  </p>
  <div class="example">
    Classification - good
    weniger Neuronen möglich?
    Classification - bad
    mehr Neuron testen, bzw mit neuen Random Variablen probieren
    Regression - good
    Regression - bad
  </div>
  
  <h3>Weights of Neurons</h3>
  <p>
    This graph shows you the total sum of all outgoing connections 
    of a neuron in relation to the most influential neuron in the 
    network, which amplifies the input that leads to a good output. 
    Note that the output layer has no weights and has been assigned 
    the value 0.7 for the graphical completeness of a network. 
    Furthermore, the individual edges have been omitted to provide 
    a better overview.
  
  
  </p>
  <div class="example">
    Due to the independence of the coordinates in the Classification - 
    circle problem, we expect them to be approximately the same size. 
    If the coordinates are dependent as in the Classification - Gaussian
     problem, where a positive coordinate automatically has a unique 
     label, we expect different sizes.
  
    Too many neurons in the subsequent layer can cause us to have two 
    neurons there that have learned the same thing, strengthen the same 
    neurons in the previous layer, but both remain the same size due to
     the equality.
    
    Neurons are changed in the process of backpropagation depending on
   their previous weight. If this is small from the start small from
    the beginning, it can also have a smaller influence later on. This
    neuron can be neglected, as other neurons have found a different
   path/dependency.
  </div>

  <h3>Average Learning Rate Change</h3>
  <p> 
    The learn rate describes the difference in total weights between two epochs.
    The layers are added together and the average is calculated. If the learning 
    rate is high, the network learns more in the epoch than if it is low. The 
    learning rate increases due to the learning rate modifier and approaches
    zero. With our data, a good network should only give one output/training
    process, otherwise adding another neuron could help.

  </p>
  
    <div class="example">
      In this graph, we can see that layers followed by a layer with many 
      neurons learn faster than layers with fewer neurons following them.
      This is due to the fact that in the backpropagation many neurons 
      adapt quickly and learn the same thing. This then adds up in the layer
      before it, which causes the learning rate to swing. 
  </div>
  <h3>Pairwise Similarity</h3>
  <p>
    The Pairwise Similarity compares the percentage distribution of the 
    weights to the next layer with other neurons in the layer. This removes
     the weight factor for each layer. As an example, [0,1] and [0,1] are 
     shown as identical with the value 1. The example [1,0] and [0,1] with
      0, and [0,1] and [1,1] with 0.5. The similarity was divided into ten bins.
  
  </p>
  <div class="example">
    For networks where all values are identical, all neurons in the same layer 
    are identical.  
  
    For independent coordinates, the input neurons should be very different 
    while dependency coordinates should be similar. Here we also see that many 
    neurons in the first and second layer are identical. Manually, one could 
    merge almost identical neurons to make the prediction of new data points 
    more favorable in terms of computational performance.
  </div>
  
  <p>
  In conclusion, a high number of similar neurons can accelerate the training
  process. However, this should not be too large, as the computing power 
  increases significantly in a fully connected network. Real world data is
  usually much more complex and requires larger networks. Networks that work
  on MNIST have an input of 28x28 pixels and 60,000 training samples.
</p>
    </div>
  </div>

  <script>
    let case_num = 0;
    let tests_aktiv = false;
    let testrunname =""
    let testarray = []
    let test_iterations = 2;
    let testtime =[];
    let memoryUsage=[];
    let timeInitWorker=[];
    let timeInitNetwork=[];
    let time_copy  =0
    let timer_send_end  =0
    let time_workerinitNetworkend =0
    let timer_worker_train_end =0
    let timer_learningRate_end =0
    let timer_showheatmap_end =0
    let timer_similarity_end =0
    let timer_network =0
    let timer_plot=0
    let max_heap = 0
    let average_heap = 0
    


    
    let workerlist = [];
    let sameWeights = 2;
    let classifier = true;
    let firstValueNeurons = [];
    let secondValueNeurons = [];
    let currentlytraining = false;
    let trainingCounterDone = 0;

    function addNetwork() {
      let networks = document.getElementById("graph_section").childElementCount;
      if (networks < 5) {
        //prepare container for graphs
        let container = document.createElement("DIV");
        container.setAttribute("id", "graph_block_" + networks)
        container.style.backgroundColor = "#eeeeee";
        container.style.height = "240px";
        container.style.display = "flex";
        container.style.padding = "auto";
        document.getElementById("graph_section").appendChild(container);
        let networkdescription = document.createElement("p");
        networkdescription.innerText = "Network " + networks;
        networkdescription.style.width = "100px";
        networkdescription.style.margin = "auto 20px";
        document.getElementById("graph_block_" + networks).appendChild(networkdescription);
        let acc_val = document.createElement("DIV");
        acc_val.setAttribute("id", "acc_val" + networks);
        acc_val.style.height = "240px";
        acc_val.style.width = "330px";
        document.getElementById("graph_block_" + networks).appendChild(acc_val);
        let network = document.createElement("DIV");
        network.setAttribute("id", "network_" + networks);
        network.style.height = "240px";
        network.style.width = "280px";
        document.getElementById("graph_block_" + networks).appendChild(network);
        let lrdgraph = document.createElement("DIV");
        lrdgraph.setAttribute("id", "lrd_" + networks);
        lrdgraph.style.height = "240px";
        lrdgraph.style.width = "300px";
        document.getElementById("graph_block_" + networks).appendChild(lrdgraph);
        let similarity_chart = document.createElement("DIV");
        similarity_chart.setAttribute("id", "similarity_" + networks);
        similarity_chart.style.height = "240px";
        similarity_chart.style.width = "250px";
        document.getElementById("graph_block_" + networks).appendChild(similarity_chart);
        
        //append to table
        let tr  = document.createElement("tr");
        tr.setAttribute("id", "input_tr_" + networks);
        document.getElementById("table").appendChild(tr);
        let td0  = document.createElement("td");
        let td1  = document.createElement("td");
        let td2  = document.createElement("td");
        let td3  = document.createElement("td");
        let td4  = document.createElement("td");
        td0.innerText = "Network "+ String(networks)+":";
        td1.innerHTML = 2
        td2.setAttribute("id","input1_td"+networks);
        td3.setAttribute("id","input2_td"+networks);
        td4.innerHTML = 2
        document.getElementById("input_tr_" + networks).appendChild(td0);
        document.getElementById("input_tr_" + networks).appendChild(td1);
        document.getElementById("input_tr_" + networks).appendChild(td2);
        document.getElementById("input_tr_" + networks).appendChild(td3);
        document.getElementById("input_tr_" + networks).appendChild(td4);
        let input1  = document.createElement("input");
        let input2  = document.createElement("input");
        input1.type = "number";
        input1.max = 8;
        input1.min = 1;
        input1.value = 2;
        input1.setAttribute("id", "input1_"+ networks);
        input2.type = "number";
        input2.max = 8;
        input2.min = 1;
        input2.value = 2;
        input2.setAttribute("id", "input2_"+ networks);
        document.getElementById("input1_td" + networks).appendChild(input1);
        document.getElementById("input2_td" + networks).appendChild(input2);
        eventLis("input1_" + networks, "input2_" + networks, networks,firstValueNeurons,secondValueNeurons);
        
      }
    }
    addNetwork();

    function openNav() {
      document.getElementById("mySidebar").style.width = "250px";
      document.getElementById("main").style.marginLeft = "250px";
      document.getElementById("openbutton").style.visibility = "hidden";
    }

    function closeNav() {
      document.getElementById("mySidebar").style.width = "0";
      document.getElementById("main").style.marginLeft = "0";
      document.getElementById("openbutton").style.visibility = "visible";
    }

    function closeNavAbout(){  
      $('#main').css("display", "none");
      $('#explanation').css("display", "none");
      $('#about').css("display","inline");
}
    function closeNavTraining(){
      $('#explanation').css("display", "none");
      $('#about').css("display", "none");
      $('#main').css("display","inline");
      closeNav();}
    function closeNavExplain(){
      $('#main').css("display", "none");
      $('#about').css("display", "none");
      $('#explanation').css("display","inline");

    }

    $("#dataset_select").change(function () {
      selectData(this.value)
    });


    $("#weights_init_select").change(function () {
      if (this.value == "weights_random"){
        sameWeights = 2
      }
      else if (this.value == "weights_equal"){
        sameWeights = 0
      }
      else {
        sameWeights = 1
      }

    });
    
    $("#networktype").change(function () {
      if (this.value == "classification"){
        classifier = true
        $(".reg").css("display", "none")
        $(".classdata").css("display", "inline")
        $("#dataset_select").val("circle_dataset");
      }
      else if (this.value == "regression"){
        classifier = false
        $(".classdata").css("display", "none")
        $(".reg").css("display", "inline")
        $("#dataset_select").val("regplain")
      }
      selectData($("#dataset_select").val())
    });

    function selectData(value){
    points = [];
      if (value == "circle_dataset"){
        classifyCircleData();
      }
      else if (value == "spiral_dataset"){
        spiral();
      }
      else if (value == "xor_dataset"){
        createXORData();
      }
      else if  (value == "gaus_dataset"){
        gaus();
      }
      else if  (value == "regplain"){
        regressionPlain();
      }
      else{
        regressionGaus();
      }
      drawDataPlot()
      schuffleData();
      //load new data
    }


    function eventLis(inputFirstLayer, inputSecondLayer, id,firstValueNeurons,secondValueNeurons){
      firstValueNeurons.push(2);
      secondValueNeurons.push(2);
      
    document.getElementById(inputFirstLayer).addEventListener("change", function () {
      let v = parseInt(this.value);
      if (v < 1) this.value = 1;
      if (v > 8) this.value = 8;
      firstValueNeurons[id-1]=(Number(this.value));  
    });

    document.getElementById(inputSecondLayer).addEventListener("change", function () {
      let v = parseInt(this.value);
      if (v < 1) this.value = 1;
      if (v > 8) this.value = 8;
      secondValueNeurons[id-1]=(Number(this.value)); 
    });}



    function removeNetwork() {
      if (document.getElementById("graph_section").childElementCount > 2) {
        let graphs = document.getElementById("graph_section");
        graphs.removeChild(graphs.lastChild);
        if (models != undefined){
        models.splice(document.getElementById("graph_section").childElementCount - 1, 1);}
        //remove entry in parameter_table nth-child(2)
        let table = document.getElementById("table");
        table.removeChild(table.lastChild);
      }
    }



    document.getElementById("trainingOnData").innerText = "Press \"Train Network\" to train the models.";


// DATA
//Domain[-10,10]
    //circle data
    function dist(a, b) {
      let dx = a.x - b.x;
      let dy = a.y - b.y;
      return Math.sqrt(dx * dx + dy * dy);
    }

    let points = [];
    let numSamples = 500;
    //change validation number value

    function classifyCircleData() {

      let radius = 10;

      function getCircleLabel(p, center) {
        return (dist(p, center) < (radius * 0.5)) ? 1 : 2;
      }

      // Generate positive points inside the circle.
      for (let i = 0; i < numSamples / 2; i++) {
        let r = Math.random() * radius / 2;
        let angle = Math.random() * 2 * Math.PI;
        let x = r * Math.sin(angle);
        let y = r * Math.cos(angle);
        let label = getCircleLabel({ x: x, y: y }, { x: 0, y: 0 });
        points.push({ x, y, label });
      }

      // Generate negative points outside the circle.
      for (let i = 0; i < numSamples / 2; i++) {
        let r = Math.random() * radius * 3 / 10 + radius * 13/20;
        let angle = Math.random() * 2 * Math.PI;
        let x = r * Math.sin(angle);
        let y = r * Math.cos(angle);
        let label = getCircleLabel({ x: x, y: y }, { x: 0, y: 0 });
        points.push({ x, y, label });
      }
    }

    function createXORData(){
      for (let i = 0; i < numSamples; i++) {
        let x = Math.random()*(16)-8;
        let y = Math.random()*(16)-8;
        let padding = 0.8;
        x += x > 0 ? padding : -padding;
        y += y > 0 ? padding : -padding;
        let label = x * y >= 0 ? 1 : 2;
        points.push({ x, y, label });
      }
    }

    function spiral(){
      let n = numSamples / 2;

      function genSpiral(delta, label) {
        for (let i = 0; i < n; i++) {
          let r = i / n * 9;
          let t = 1.75 * i / n * 2 * Math.PI + delta;
          let x = r * Math.sin(t);
          let y = r * Math.cos(t);
          points.push({x, y, label});
        }
      }
      genSpiral(0,1);
      genSpiral(Math.PI,2);
    }

    function gaus(){
      function normalRandom(mean = 0){
        let v1 = 0;
        let v2 = 0;
        let s = 0;
        do {
          v1 = 6 * Math.random() - 3;
          v2 = 6 * Math.random() - 3;
          s = v1 * v1 + v2 * v2;
        } while (s > 3);
        let result = Math.sqrt(-2 * Math.log((s/3)) / (s/2)) * v1;
        return mean + result;
      };
      function createGaus(cx, cy, label){
      for (let i = 0; i < numSamples / 4; i++) {
      let x = normalRandom(cx);
      let y = normalRandom(cy);
      points.push({x, y, label});
    }
  };

  createGaus(4.5, 4.5, 1); // Gaussian with positive examples.
  createGaus(-4.5, -4.5, 2);

    }

    function regressionPlain(){
      let moreSamples = numSamples*2
      for (let i = 0; i<moreSamples; i++){
        let x = Math.random()*20-10;
        let y = Math.random()*20-10;
        let label = (x+y)/20
        points.push({x, y, label})
      }
    }

    function schuffleData() {

      for (var i = points.length - 1; i > 0; i--) {
        var j = Math.floor(Math.random() * (i + 1));
        var temp = points[i];
        points[i] = points[j];
        points[j] = temp;
      }
    }
    
    function regressionGaus(){
      let gaussians = [
        [-7,4,1],
        [0,4,-1],
        [7,4,1],
        [-7,-4,-1],
        [0,-4,1],
        [7,-4,-1]
      ]
      let moreSamples = numSamples*2
      for (let i=0; i <moreSamples; i++){
        let x = Math.random()*20-10;
        let y = Math.random()*20-10;
        let label = 10
        for (let j = 0; j < 6; j++){
          let clothestPoint = gaussians[j][2]*(dist({x,y},{x:gaussians[j][0],y:gaussians[j][1]}))
          if (Math.abs(clothestPoint) < Math.abs(label)) {
            label = clothestPoint;
          }
        }
        if (label > 0 ){
          label = 1-(label/Math.sqrt(45))
        }else{
          label = -1-(label/Math.sqrt(45))
        }
        points.push({x:x, y:y, label:label})
      }
    }
    
    function drawDataPlot(){
    let dataSpec
    if ($("#networktype").val() == "classification"){
    dataSpec = {
      "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
      "description": "A simple scatter plot to display circle data.",
      "data": {
        "values": points,
      },

      "mark": "point",
      "title":"Current Dataset",
      "width": 150,
      "height": 150,
      "background": "#eeeeee",
      "view": {"fill": "#f9f9f9"},
      "encoding": {
        "x": { "field": "x", "type": "quantitative", "axis":{"title":"X-Value"},"scale":{"domain":[-10,10]} },
        "y": { "field": "y", "type": "quantitative", "axis":{"title":"Y-Value"},"scale":{"domain":[-10,10]} },
        "color": { "field": "label",
                    "scale": {"range":["#d95f02", "#7570b3"],
                              "domain": [1,2] },
                              "legend": {
                                        "labelExpr": "datum.label == 1 ? 'Class 1' : datum.label == '2' ? 'Class 2' : 'error'",
                                          },
                              "title":"Point of"},

        "tooltip": [{ "field": "label", "title":"Class Label" },{ "field": "x","title":"X-Value" }, { "field": "y","title":"Y-Value" }, ],
      
      
      
      },


    };}
    else{
      dataSpec= {"$schema": "https://vega.github.io/schema/vega-lite/v5.json",
      "description": "A simple scatter plot to display circle data.",
      "data": {
        "values": points,
      },

      "mark": "point",
      "title":"Current Dataset",
      "width": 150,
      "height": 150,
      "background": "#eeeeee",
      "view": {"fill": "#f9f9f9"},
      "encoding": {
        "x": { "field": "x", "type": "quantitative", "axis":{"title":"X-Value"},"scale":{"domain":[-10,10]} },
        "y": { "field": "y", "type": "quantitative", "axis":{"title":"Y-Value"},"scale":{"domain":[-10,10]} },
        "color": { "field": "label", "type":"quantitative", "title":"Value","scale": {
        "domainMid": 0,
        "range": "diverging"
      }},

        "tooltip": [{ "field": "label", "title":"Value" },{ "field": "x","title":"X-Value" }, { "field": "y","title":"Y-Value" }, ],    
      },}
    }

    vegaEmbed("#dataplot", dataSpec, {renderer: "svg", actions:false});
  }

  let trainingData = []
  let outputData = []
  function convertdata (){
    trainingData = tf.tensor2d(points.map(item => [item.x, item.y]));
    if (classifier){
    outputData = tf.tensor(points.map(item => [
      item.label == 1 ? 1 : 0,
      item.label == 2 ? 1 : 0,
    ]));}
    else{
      outputData = tf.tensor(points.map(item => [item.label]))
    }
  }
 classifyCircleData();
schuffleData();
drawDataPlot()
convertdata()

    // convert input
    // Create a Tensorflow Model
    const bias = true;
  
    async function initNetwork(model, firstLayer, secondLayer, sameWeights, classifier) {
    model = tf.sequential();

    function setinitWeights(a,b,layer){
      let weight_array = []
      for (let index_a = 0; index_a < a; index_a++){
        for (let index_b = 0; index_b < b; index_b++){
          weight_array.push((1+index_b)/b)
        }
      }
      let tensor = tf.tensor(weight_array,[a,b])
      model.layers[layer].setWeights([tensor,tf.zeros([b])])
    }

    if (classifier){
    model.add(tf.layers.dense({ inputShape: [2], useBias: true, units: firstLayer, activation: "sigmoid" }));
    model.add(tf.layers.dense({ units: secondLayer, useBias: true, activation: "sigmoid" }));
    model.add(tf.layers.dense({ units: 2, useBias: true, activation: "softmax" }));
    }else{
    model.add(tf.layers.dense({ inputShape: [2], useBias: true, units: firstLayer, activation: "tanh" }));
    model.add(tf.layers.dense({ units: secondLayer, useBias: true, activation: "tanh" }));
    model.add(tf.layers.dense({ units: 1, useBias: true, activation: "tanh" }));
    }
    if (sameWeights == 0){
      let init_weights_input = tf.fill([2, firstLayer], 0.5)
      let init_weights_first = tf.fill([firstLayer, secondLayer], 0.5)
      let init_weights_second = tf.fill([secondLayer, 2], 0.5)
      model.layers[0].setWeights([init_weights_input,tf.zeros([firstLayer])])
      model.layers[1].setWeights([init_weights_first,tf.zeros([secondLayer])])
      model.layers[2].setWeights([init_weights_second,tf.zeros([2])])
    }
    else if (sameWeights == 1){
      setinitWeights(2,firstLayer,0);
      setinitWeights(firstLayer,secondLayer,1);
      setinitWeights(secondLayer,2,2);
    }   
    
    model.compile({ loss: "meanSquaredError", optimizer: tf.train.adam(.01), metrics: ["acc"] });
    return model
  }

    async function training(model, network_index, classifier) {
      let acc = [];
      let plot3 = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "A simple scatter plot to display circle data.",
        
        "title": "Traing process",
        "background": "#eeeeee",
      
        "vconcat": [{
          "view": {"fill": "#f9f9f9"},
          "width": 150,
          "height": 150,
          "data": {
            "values": acc,
          },
          "encoding": {
            "x": { "field": "epoch", "type": "quantitative", "title": "Epoch" }
          },
          "layer": [{
            "mark": "line",
            "encoding": {
              "y": { "field": "value", "type": "quantitative", "title": "Value", "scale":{"domain":[0,1]}, },
              "color":{"field":"type", "type":"nominal",
                "scale":{"range":["#33a02c","#1f78b4","#a6cee3","#b2df8a"],
                          "domain":["acc","val_acc","loss","val_loss"]},
                "legend": {"labelExpr": "datum.label == 'acc' ? 'Accuricity' :datum.label == 'loss' ? 'Loss Value' :datum.label == 'val_acc' ? 'Validation Accuricity' : 'Loss Validation'"
            },
            "title":"Training Values",
          }
            }
          },
          {
            "params": [{
              "name": "hover",
              "select": {
                "type": "point",
                "fields": ["epoch"],
                "nearest": true,
                "on": "pointermove",
                "clear": "pointerout"
              }
            }],
            "transform": [{ "pivot": "type", "value": "value", "groupby": ["epoch"] }],
            "mark": "rule",
            "encoding": {
              "tooltip": [{ "field": "epoch", "type": "quantitative", "title": "Epoch" },
              { "field": "acc", "type": "quantitative", "title": "Accuracy" },
              { "field": "val_acc", "type": "quantitative", "title": "Validation_Accuracy" },
              { "field": "loss", "type": "quantitative", "title": "loss" },
              { "field": "val_loss", "type": "quantitative", "title": "Validation_loss" }],
              "opacity": {
                "condition": { "value": 1, "param": "hover", "empty": false },
                "value": 0.0
              }
            }
          }]
        }

        ]
      }

      async function learningRateDecay( prevLayer, input, firstLayer, secondLayer){
  function diff(prevLayer, actLayer){
    let lRateDecay = 0;
    for (let i = 0; i< actLayer.length; i++){
      for (let j = 0;j<actLayer[0].length;j++){
      lRateDecay += Math.abs(prevLayer[i][j]-actLayer[i][j]);
    }}
    return (lRateDecay/actLayer.length)
  }
  let layer_input = diff(prevLayer[0], input);
  let layer_H1 =diff(prevLayer[1], firstLayer);
  let layer_H2 =diff(prevLayer[2], secondLayer);
  return [layer_input < 0.6?layer_input:0.6,layer_H1< 0.6?layer_H1:0.6,layer_H2< 0.6?layer_H2:0.6]

}

async function showheatmap(id, input, firstLayer, secondLayer, classifier){
  let data_weights = []; 
  let all_weights = [input, firstLayer, secondLayer]
  let layer_name =""
  let max_node_weight  = 0 
  for (let layer = 0; layer < 3; layer++){
    let number_neurons = all_weights[layer].length;
    for (let neuron = 0; neuron < number_neurons; neuron++){
      let weights = all_weights[layer][neuron].length;
      let weight_sum = 0;
      for (let weight = 0; weight < weights; weight++){
        weight_sum += Math.abs(all_weights[layer][neuron][weight]);
      } 
      if (weight_sum > max_node_weight){max_node_weight = weight_sum}
    } 
  }
  for (let layer = 0; layer < 3; layer++){
    if (layer == 0){ layer_name = "Input Layer"}
    else if (layer == 1){layer_name ="First Layer"}
    else if (layer == 2){layer_name ="Second Layer"}
    let number_neurons = all_weights[layer].length;
    for (let neuron = 0; neuron < number_neurons; neuron++){
      let weights = all_weights[layer][neuron].length;
      let weight_sum = 0;
      for (let weight = 0; weight < weights; weight++){
        weight_sum += Math.abs(all_weights[layer][neuron][weight]);
      }
      let scaled_weight_sum = weight_sum/max_node_weight
      let yposition = ((neuron+1)/(number_neurons+1));
      data_weights.push({"layer":layer_name,"yposition":yposition, "weight":scaled_weight_sum,"neuron":neuron})
    }

  }
  if (classifier){
  data_weights.push({"layer":"Output Layer","yposition":0.33, "weight":0.7,"neuron":0});
  data_weights.push({"layer":"Output Layer","yposition":0.67, "weight":0.7,"neuron":1});}
  else{
    data_weights.push({"layer":"Output Layer","yposition":0.5, "weight":0.7,"neuron":0});
  }
  plot_heat(id, data_weights)

}
async function similarity(id, layers){
function sort_dissimilarity_revers(d2array) {
  let minimum = d2array[0].length * 2;
  let clothesthneighbour = 1;
  let d2arraylen = d2array.length;
  let d2outarraylen = d2array[0].length;
  let reverse = false;
  for (let outarray = 1; outarray < d2arraylen; outarray++) {
    let euklidsum = 0;
    let euklidsum_revers = 0;
    for (let inarray = 0; inarray < d2outarraylen; inarray++) {
      euklidsum += Math.abs(d2array[0][inarray] - d2array[outarray][inarray]);
      euklidsum_revers += Math.abs(d2array[0][inarray] + d2array[outarray][inarray]);
    }
    if (euklidsum < euklidsum_revers) {
      if (euklidsum < minimum) {
        minimum = euklidsum;
        clothesthneighbour = outarray;
        reverse = false;
      }
    }
    else if (euklidsum_revers < minimum) {
      minimum = euklidsum_revers;
      clothesthneighbour = outarray;
      reverse = true;
    }
  }
  let scaled_minimum = Math.floor(10*(1-(minimum/d2outarraylen)))/10
  return [clothesthneighbour, reverse, scaled_minimum.toString()]
}

function scaleData(predata){
//scale down to 1max
//create 1D array with max/min
let maxRow = predata.map(function (row) { return Math.max.apply(Math, row); });
let minRow = predata.map(function (row) { return Math.min.apply(Math, row); });
let max_row_length = maxRow.length;
var scaleddata = [];
//scale with Math.max(maxRow, Math.abs(minRow))
for (let i = 0; i < max_row_length; i++) {
  if (Math.abs(maxRow[i]) > Math.abs(minRow[i])) {
    var scale = Math.abs(maxRow[i]);
  }
  else {
    var scale = Math.abs(minRow[i]);
  }
  var helper = predata[i].map(x => x / scale);
  scaleddata.push(helper);
}
return scaleddata
}

let similarity_array = []
for (let i = 0; i < layers.length; i++){
let switched_signs = scaleData(layers[i]);
let iterations = switched_signs.length - 1;
for (let index = 0; index < iterations; index++) {
  var result = sort_dissimilarity_revers(switched_signs.slice(index, switched_signs.length));
  if (result[0] != 1) {
    let rowhelper3 = switched_signs[result[0] + index];
    switched_signs[result[0] + index] = switched_signs[index + 1];
    switched_signs[index + 1] = rowhelper3;
  }
  if (result[1]) {
    switched_signs[index + 1] = await switched_signs[index + 1].map(el => -el);
  }
  similarity_array.push({"layerID":i, "similarity":result[2]});
}
}
plot_similarity(id, similarity_array)
}

      let learningRate = [];
      let prevLayer = [await model.getWeights()[0].array(), await model.getWeights()[2].array(), await model.getWeights()[4].array()]

      let networkID = document.getElementById("acc_val" + (network_index + 1));
    const startTime = Date.now();
      const h = await model.fit(trainingData, outputData, {
        epochs: 10,
        //shuffle:true,
        validationSplit: 0.2,
        callbacks: [{
          onEpochEnd: async (epoch, logs) => {
            let input = await model.getWeights()[0].array()
        let firstLayer = await model.getWeights()[2].array()
        let secondLayer = await model.getWeights()[4].array()
        if (classifier){
          acc.push({ epoch: epoch, value: logs.val_loss, type: "val_loss" });
        acc.push({ epoch: epoch, value: logs.loss, type: "loss" });
        acc.push({ epoch: epoch, value: logs.val_acc, type: "val_acc" });
        acc.push({ epoch: epoch, value: logs.acc, type: "acc" });
      }else{
      acc.push({ epoch: epoch, value: logs.val_loss < 0.6? logs.val_loss: 0.6, type: "val_loss" });
      acc.push({ epoch: epoch, value: logs.loss < 0.6? logs.loss: 0.6, type: "loss" });
    }

        learningRate_values = await learningRateDecay( prevLayer, input, firstLayer, secondLayer)
        learningRate.push({epoch:epoch, value:learningRate_values[0], type:"input"})
        learningRate.push({epoch:epoch, value:learningRate_values[1], type:"hidden1"})
        learningRate.push({epoch:epoch, value:learningRate_values[2], type:"hidden2"})
        prevLayer = [input, firstLayer, secondLayer]

        if (epoch%2==0){
        plot_training(network_index, acc)
        plot_lrd(network_index, learningRate)
        }
        if (epoch%10 == 0){
          showheatmap(network_index, input, firstLayer, secondLayer, classifier)

          similarity(network_index, [input, firstLayer, secondLayer])
        }
        }
        },
          //callback
        ]
      });

    }


    function plot_training(id, acc){
      let timer_plot_start = performance.now()
      let networkID = document.getElementById("acc_val"+(id+1));
      let plot3
      if ($("#networktype").val() == "classification"){
      plot3 = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "Display of trainingsprocess.",
        "background": "#eeeeee",
      
        "title": "Traing process",
        "vconcat": [{
          "view": {"fill": "#f9f9f9"},
          "width": 150,
          "height": 150,
          "data": {
            "values": acc,
          },
          "encoding": {
            "x": { "field": "epoch", "type": "quantitative", "title": "Epoch" }
          },
          "layer": [{
            "mark": "line",
            "encoding": {
              "y": { "field": "value", "type": "quantitative", "title": "Value", "scale":{"domain":[0,1]}, },
              "color":{"field":"type", "type":"nominal",
                "scale":{"range":["#33a02c","#1f78b4","#a6cee3","#b2df8a"],
                          "domain":["acc","val_acc","loss","val_loss"]},
                "legend": {"labelExpr": "datum.label == 'acc' ? 'Accuricity' :datum.label == 'loss' ? 'Loss Value' :datum.label == 'val_acc' ? 'Validation Accuricity' : 'Loss Validation'"
            },
            "title":"Training Values",
          }
            }
          },
          {
            "params": [{
              "name": "hover",
              "select": {
                "type": "point",
                "fields": ["epoch"],
                "nearest": true,
                "on": "pointermove",
                "clear": "pointerout"
              }
            }],
            "transform": [{ "pivot": "type", "value": "value", "groupby": ["epoch"] }],
            "mark": "rule",
            "encoding": {
              "tooltip": [{ "field": "epoch", "type": "quantitative", "title": "Epoch" },
              { "field": "acc", "type": "quantitative", "title": "Accuracy" },
              { "field": "val_acc", "type": "quantitative", "title": "Validation_Accuracy" },
              { "field": "loss", "type": "quantitative", "title": "loss" },
              { "field": "val_loss", "type": "quantitative", "title": "Validation_loss" }],
              "opacity": {
                "condition": { "value": 1, "param": "hover", "empty": false },
                "value": 0.0
              }
            }
          }]
        }

        ]
      }
    }
      else{
        plot3 = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "A simple scatter plot to display circle data.",
        "background": "#eeeeee",
      
        "title": "Traing process",
        "vconcat": [{
          "view": {"fill": "#f9f9f9"},
          "width": 150,
          "height": 150,
          "data": {
            "values": acc,
          },
          "encoding": {
            "x": { "field": "epoch", "type": "quantitative", "title": "Epoch" }
          },
          "layer": [{
            "mark": "line",
            "encoding": {
              "y": { "field": "value", "type": "quantitative", "title": "Value", "scale":{"domain":[0,0.5]}, },
              "color":{"field":"type", "type":"nominal",
                "scale":{"range":["#33a02c","#1f78b4"],
                          "domain":["loss","val_loss"]},
                "legend": {"labelExpr": "datum.label == 'loss' ? 'Loss Value' : 'Loss Validation'"
            },
            "title":"Training Values",
          }
            }
          },
          {
            "params": [{
              "name": "hover",
              "select": {
                "type": "point",
                "fields": ["epoch"],
                "nearest": true,
                "on": "pointermove",
                "clear": "pointerout"
              }
            }],
            "transform": [{ "pivot": "type", "value": "value", "groupby": ["epoch"] }],
            "mark": "rule",
            "encoding": {
              "tooltip": [{ "field": "epoch", "type": "quantitative", "title": "Epoch" },
              { "field": "loss", "type": "quantitative", "title": "loss" },
              { "field": "val_loss", "type": "quantitative", "title": "Validation_loss" }],
              "opacity": {
                "condition": { "value": 1, "param": "hover", "empty": false },
                "value": 0.0
              }
            }
          }]
        }

        ]
      }
      }
      vegaEmbed(networkID, plot3, {renderer: "svg", actions:false});
      timer_plot += (performance.now()-timer_plot_start)/test_iterations
    }
  //}

    //function plot_heat(networks, data_weights, epoch){
    function plot_heat(id, data_weights){
    //for (let i = 0; i < networks; i++){
    let timer_plot_start = performance.now()
    let networkIDheatmap = document.getElementById("network_" + (id + 1));
    let plotheatmap = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "Displaying the Weights of Nodes",
        "background": "#eeeeee",
      "view": {"fill": "#f9f9f9"},
        "title": "Weights of Neurons",

          "width": 150,
          "height": 150,
          "data": {
            "values": data_weights,
          },
          "encoding": {
            "x": { 
              "field": "layer", 
              "type": "ordinal",
              "axis": { "title":"","labelAngle":40},
              "sort":["Input Layer","First Layer","Second Layer","Output Layer"] },
            "y": { 
              "field": "yposition", 
              "type": "quantitative",
              "axis": {
                "ticks": false,
                "labels":false,
                "title":"",
                },
              "scale":{"domain":[1,0]},
              },
            "size":{
              "field":"weight",
              "type":"quantitative",
              "title":"Influence of Node"
            },
            "tooltip":[
              {"field":"layer", "type":"ordinal", "title":"Layer"},
              {"field":"neuron", "type":"qualitative", "title":"Neuron"},
              {"field":"weight", "type":"qualitative", "title":"Weight"}
            ]
          },
            "mark": "circle",
            "config": {"axis": {"grid": false}}
            }
            vegaEmbed(networkIDheatmap, plotheatmap, {renderer: "svg", actions:false});
            timer_plot += (performance.now()-timer_plot_start)/test_iterations

  }

  function plot_lrd(id, lrd){
    let timer_plot_start = performance.now()
      let networkID = document.getElementById("lrd_"+(id+1));
      let lrdplot = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "description": "A simple scatter plot to display circle data.",
        "background": "#eeeeee",
        
        "title": "Average Learning Rate Change per Layer",
        "vconcat": [{
          "view": {"fill": "#f9f9f9"},
          "width": 150,
          "height": 150,
          "data": {
            "values": lrd,
          },
          "encoding": {
            "x": { "field": "epoch", "type": "quantitative", "title": "Epoch" }
          },
          "layer": [{
            "mark": "line",
            "encoding": {
              "y": { "field": "value", "type": "quantitative", "title": "Learning Rate", "scale":{"domain":[0,0.6]}, },
              "color":{"field":"type", "type":"nominal",
                "scale":{"range":["#7570b3","#d95f02","#a6cee3","#1b9377"],
                          "domain":["input","hidden1","hidden2"]},
                "legend": {"labelExpr": "datum.label == 'input' ? 'Input Layer' :datum.label == 'hidden1' ? 'First Layer' : 'Second Layer'"
            },
            "title":"Layer",
          }
            }
          },
          {
            "params": [{
              "name": "hover",
              "select": {
                "type": "point",
                "fields": ["epoch"],
                "nearest": true,
                "on": "pointermove",
                "clear": "pointerout"
              }
            }],
            "transform": [{ "pivot": "type", "value": "value", "groupby": ["epoch"] }],
            "mark": "rule",
            "encoding": {
              "tooltip": [{ "field": "epoch", "type": "quantitative", "title": "Epoch" },
              { "field": "input", "type": "quantitative", "title": "Input Layer" },
              { "field": "hidden1", "type": "quantitative", "title": "Hidden Layer 1" },
              { "field": "hidden2", "type": "quantitative", "title": "Hidden Layer 2" },],
              "opacity": {
                "condition": { "value": 1, "param": "hover", "empty": false },
                "value": 0.0
              }
            }
          }]
        }

        ]
      }
      vegaEmbed(networkID, lrdplot, {renderer: "svg", actions:false});
      timer_plot += (performance.now()-timer_plot_start)/test_iterations
    }

    function plot_similarity(id, switched_signs){
      let timer_plot_start = performance.now()
      let networkID = document.getElementById("similarity_"+(id+1));
      let similarity_chart= {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
          "data":{"values":switched_signs},
          "mark": "bar",
          "title":{
            "text":"Pairwise Similarity in the same Layer",
            "offset":8},
          "width":150,
          "height":150,
          "background": "#eeeeee",
      "view": {"fill": "#f9f9f9"},
          "encoding": {
            "x": {"field": "similarity", "title":"Similarity"},
            "y": {"aggregate":"count", "type": "quantitative"},
            "xOffset": {"field": "layerID"},
            "color": {"field": "layerID", "title":"Layer",
            "scale":{"range":["#7570b3","#d95f02","#a6cee3","#1b9377"],
                          },
            "legend":{"labelExpr": "datum.label == '0' ? 'Input Layer' :datum.label == '1' ? 'First Layer' : 'Second Layer'"
          } }
        }
        }
      

        let similarity_chart2= {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "repeat": {"layer": ["0","1","2"]},
        "background": "#eeeeee",
      "view": {"fill": "#f9f9f9"},
        "spec": {
          "mark": "bar",
          "encoding": {
            "x": {
              "field": "similarity",
              "title": "Similarity",
              "type": "nominal"
            },
            "y": {
              "aggregate": "count",
              "field": {"repeat": "layer"},
              "title": "Sim in Percentage"
            },
            "color": {"datum": {"repeat": "layer"}, "title": "Layer"},
            "xOffset": {"datum": {"repeat": "layer"}}
          }
        },
        "config": {
          "mark": {"invalid": null}
        }}

      vegaEmbed(networkID, similarity_chart, {renderer: "svg", actions:false});
      timer_plot += (performance.now()-timer_plot_start)/test_iterations
    }

    function training_done(){
      trainingCounterDone++
      if (document.getElementById("graph_section").childElementCount-1 == trainingCounterDone){
      document.getElementById("trainingOnData").innerText = "The training was finished.";
      trainingCounterDone = 0
      currentlytraining = false
      }
    }

    //check if the smallest dataset got new elements
    function checkForEpoch(array, id){
      for (let i = 0; i < array.length; i++){
        if (array[i].length > array[id].length){
          return false
        }
      }
      return true
    }

    //Worker --allow-file-access-from-files
    async function initWorker(networks){
      let acc = [];
      let heat = [];
      for (let i = 0 ; i < networks; i++){
        acc.push([]);
        heat.push([]);
      }
      for (let i = 0; i<4; i++){
        const worker = await new Worker("worker.js");
        worker.addEventListener("message", function handleMessageFromWorker(msg){
          if (msg.data[1] == "acc"){
              plot_training(msg.data[0], msg.data[2]);

          }
          else if (msg.data[1] == "heatmap"){
              plot_heat(msg.data[0], msg.data[2]);
              heap()
          }
          else if (msg.data[1] == "lrd"){
              plot_lrd(msg.data[0], msg.data[2]);
          }
          else if (msg.data[1]=="similarity"){
            plot_similarity(msg.data[0], msg.data[2])

          }
          else if (msg.data[1]=="measurments"){
            console.log(msg.data[2])
            time_copy += msg.data[2][0]/test_iterations
            timer_send_end += msg.data[2][1]/test_iterations
            time_workerinitNetworkend+= msg.data[2][2]/test_iterations
            timer_worker_train_end+= msg.data[2][3]/test_iterations
            timer_learningRate_end+= msg.data[2][4]/test_iterations
            timer_showheatmap_end+= msg.data[2][5]/test_iterations
            timer_similarity_end+= msg.data[2][6]/test_iterations
            timer_network+= msg.data[2][7]/test_iterations

          }
          else if (msg.data[1]=="done"){
            if (tests_aktiv){
              training_done2_test()
            }
            else{
            training_done()
          }
        }
      })
        workerlist.push(worker)
      }
      return workerlist
    }

    async function startTraining2(){
      let networks = document.getElementById("graph_section").childElementCount - 1;
      if (workerlist.length == 0){workerlist = await initWorker(networks)}

      if (!currentlytraining){
    currentlytraining = true;
    document.getElementById("trainingOnData").innerText = "The training has started!";
    for (let j = 0; j < networks; j++) {
      workerlist[j].postMessage({id:j, firstLayer:firstValueNeurons[j], secondLayer:secondValueNeurons[j], sameWeights:sameWeights, data:points, classifier:classifier})     
    }
  }
    }


    var models;
    var model_training;


    //let prediction = model.predict(tf.tensor2d([[150.0,150.0],[0,0],[10,10],[100,100],[20,-100]]));

//ctr + r, chrome --enable-precise-memory-info
//https://jsfiddle.net/asmgdb06/
//Application Test
let timeInitWorker_start
let timeInitWorker_End
let start 
let training_elements  =0;

async function startTraining2_test(firstValueNeurons, secondValueNeurons, num_net){
  training_elements = num_net  
  timeInitWorker_start = performance.now()
      if (workerlist.length == 0){workerlist = await initWorker(num_net)}
    timeInitWorker_End = performance.now()-timeInitWorker_start
    //push(timeInitWorker_End)
    start = Date.now()
    for (let j = 0; j < num_net; j++) {
      workerlist[j].postMessage({id:j, firstLayer:firstValueNeurons[j], secondLayer:secondValueNeurons[j], sameWeights:sameWeights, data:points, classifier:classifier, start:start})     
    }
  }

async function training_done2_test(){
      trainingCounterDone++
      if (training_elements == trainingCounterDone){
      trainingCounterDone = 0
      uJSHS = window.performance.memory.usedJSHeapSize;
      let end = performance.now();
      memoryUsage.push(uJSHS);
      testtime.push(end-start);
      testarray[case_num] += 1;
      let [firstValueNeurons, secondValueNeurons, num_net] = await changeInputClassification(testarray)
      
    if (firstValueNeurons == 0){
        store_eval()
      }
    else {
      startTraining2_test(firstValueNeurons, secondValueNeurons, num_net)
    }
    }
  }

function heap(){
  let heapsize = window.performance.memory.usedJSHeapSize
  if (heapsize > max_heap){
    max_heap = heapsize
  }
  average_heap += heapsize/(test_iterations*6*training_elements)
  //6 = 0,10,20,30,40,50
}
function resetValues(){  

  testtime=[]
  memoryUsage=[]
  timeInitWorker=[]
  timeInitNetwork = []
  time_copy  =0
    timer_send_end  =0
    time_workerinitNetworkend =0
    timer_worker_train_end =0
    timer_learningRate_end =0
    timer_showheatmap_end =0
    timer_similarity_end =0
    timer_network =0
    timer_plot=0
    average_heap =0
    max_heap = 0

  }



let test_case = 2;
let parallel = false;
async function getTestResults() {
  tests_aktiv = true;
  testarray = [0,0,0,0]
  case_num = 0
  resetValues()

  if (test_case==0){
  testrunname = "Classification_SingleThread"
  classifier = true
  getTestResultsRec(array = [0,0,0,0])}

  if (test_case==1){
  testrunname = "Regression_SingleThread"
  classifier = false
  selectData("regplain")
  convertdata()
  getTestResultsRec(array = [0,0,0,0])}

  if (test_case==2){
  parallel = true
  selectData("circle_dataset")
  testrunname = "Classification_MultiThread"
  classifier = true
  startTraining2_test([2], [2], 1)}

  //if (test_case==3){
  //  parallel = true
  //selectData("regplain")
  //testrunname = "Regression_MultiThread"
  //classifier = false
  //startTraining2_test([2], [2], 1)
//}
}

  async function changeInputClassification(testarray){
    if (testarray[0]<test_iterations){
    let [firstValueNeurons, secondValueNeurons] = [[2], [2]];
      return [firstValueNeurons, secondValueNeurons,1]
  }
  if (testarray[0]==test_iterations){
    case_num++
    testarray[0]++
    store_eval(0)
    
  }

  if(testarray[1]<test_iterations){
    let [firstValueNeurons, secondValueNeurons] = [[8], [8]];
    return [firstValueNeurons, secondValueNeurons,1]
  }
  if (testarray[1]==test_iterations){
    store_eval(1)
    case_num++
    testarray[1]++
  addNetwork();
  addNetwork();
  addNetwork();
  window.scrollTo(0, document.body.scrollHeight);
}

  if(testarray[2]<test_iterations){
    let [firstValueNeurons, secondValueNeurons] = [[2,2,2,2], [2,2,2,2]];
    return [firstValueNeurons, secondValueNeurons,4]
  }
  if (testarray[2]==test_iterations){
    store_eval(2)
    case_num++
    testarray[2]++}

  if(testarray[3]<test_iterations){
    let [firstValueNeurons, secondValueNeurons] = [[8,8,8,8], [8,8,8,8]];
    return [firstValueNeurons, secondValueNeurons,4]
  }
  
  store_eval(3)
  test_case++
getTestResults(test_case)

}
 
  async function getTestResultsRec(testarray) {
    
    [firstValueNeurons, secondValueNeurons, num_net] = await changeInputClassification(testarray)
    let start = performance.now();
    document.getElementById("trainingOnData").innerText = "The training has started!";
    model_training=[];
    models = [];
    let inittime= 0
    for (let j = 0; j < num_net; j++) {
      let time_init_network_start = performance.now()
      let model = await initNetwork(models[j], firstValueNeurons[j], secondValueNeurons[j], 2, classifier);
      models.push(model);    
      let time_init_network_end = performance.now() - time_init_network_start
      inittime += time_init_network_end 
    }
    timeInitNetwork.push(inittime/num_net)
    let time_start_network_training = performance.now()
    for (let j = 0; j < num_net; j++) {
    model_training.push(new Promise((resolve, reject) => {resolve(training(models[j], j, classifier))}));
    }

    Promise.all(model_training).then(() => {
      document.getElementById("trainingOnData").innerText = "The trainings process is done!";
      uJSHS = window.performance.memory.usedJSHeapSize;}).then(()=>{
      let end = performance.now();
      //push("time":,"ram":, "case_number:")
      //memoryUsage.push({"ram":uJSHS, "time":end-start,"case_number":case_num});
      memoryUsage.push(uJSHS);
      testtime.push(end-start);
      //push.
      testarray[case_num] += 1;
      getTestResultsRec(testarray)
    }) 
  

}

function store_eval(neuronNum){
//  let timeName = testrunname + "_Time"
//  let memoryUsageName = testrunname + "_memoryUsage"

//localStorage.setItem(timeName, JSON.stringify(testtime));
//localStorage.setItem(memoryUsageName, JSON.stringify(memoryUsage));

//console.log(timeName, memoryUsageName)
console.log("Testrun done")
let result_storage = 
  [
  test_case,
  time_copy,
  timer_send_end,
  time_workerinitNetworkend,
  timer_worker_train_end,//all
  timer_learningRate_end,
  timer_showheatmap_end,
  timer_similarity_end,
  timer_network, 
  timer_plot,
  max_heap,
  average_heap,
  ]
  let storage_name = String(test_case) + String(neuronNum)
  console.log(storage_name)
localStorage.setItem(storage_name, JSON.stringify(result_storage));
resetValues()
//jsheap: sum(every 10/5)

}

function showTestResults(){
  //console.log(JSON.parse(localStorage.getItem("testtime")))
  //console.log("memoryUsage "+JSON.parse(localStorage.getItem("memoryUsage")))
  console.log("23: "+JSON.parse(localStorage.getItem(23)))
//Regression_SingleThread_Time
//Regression_SingleThread_memoryUsage
}


  </script>


</body>

</html>